{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have collected data about a set of patients, all of whom suffered from the same illness. During their course of treatment, each patient responded to one of 5 medications, Drug A, Drug B, Drug C, Drug X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>8.607</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>16.275</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>11.037</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>15.171</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>19.368</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0   23   F    HIGH        HIGH   25.355  drugY\n",
       "1   47   M     LOW        HIGH   13.093  drugC\n",
       "2   47   M     LOW        HIGH   10.114  drugC\n",
       "3   28   F  NORMAL        HIGH    7.798  drugX\n",
       "4   61   F     LOW        HIGH   18.043  drugY\n",
       "5   22   F  NORMAL        HIGH    8.607  drugX\n",
       "6   49   F  NORMAL        HIGH   16.275  drugY\n",
       "7   41   M     LOW        HIGH   11.037  drugC\n",
       "8   60   M  NORMAL        HIGH   15.171  drugY\n",
       "9   43   M     LOW      NORMAL   19.368  drugY"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "drug_data = pd.read_csv('drug200.csv')\n",
    "drug_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We want to try split into 2 different dataset (70% / 30%) and evaluate the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. We want to convert the string into label (Sex, BP, NA_to_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label = preprocessing.LabelEncoder()\n",
    "new_sex = label.fit_transform(drug_data['Sex'])\n",
    "#print(f\"sex_label = {new_sex}\")\n",
    "\n",
    "new_BP = label.fit_transform(drug_data['BP'])\n",
    "#print(f\"BP_label = {new_BP}\")\n",
    "\n",
    "new_Cholesterol = label.fit_transform(drug_data['Cholesterol'])\n",
    "#print(f\"Cholesterol_label = {new_Cholesterol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HIGH', 'NORMAL'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_data['Cholesterol'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert df into array so we can train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explanatory Variable (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23, 'F', 'HIGH', 'HIGH', 25.355],\n",
       "       [47, 'M', 'LOW', 'HIGH', 13.093],\n",
       "       [47, 'M', 'LOW', 'HIGH', 10.113999999999999]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = drug_data[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values\n",
    "X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23, 0, 0, 0, 25.355],\n",
       "       [47, 1, 1, 0, 13.093],\n",
       "       [47, 1, 1, 0, 10.113999999999999],\n",
       "       [28, 0, 2, 0, 7.797999999999999],\n",
       "       [61, 0, 1, 0, 18.043]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,1] = new_sex\n",
    "X[:,2] = new_BP\n",
    "X[:,3] = new_Cholesterol\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Response Variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['drugY', 'drugC', 'drugC'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = drug_data['Drug'].values\n",
    "y[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 = Gini Decision Tree Model (Random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model1 = DecisionTreeClassifier(criterion=\"gini\", max_depth = 4)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction output is ['drugX' 'drugY' 'drugX' 'drugC' 'drugY'], meanwhile the real output we have is ['drugX' 'drugY' 'drugX' 'drugC' 'drugY']\n"
     ]
    }
   ],
   "source": [
    "Model1.fit(X_train, y_train)\n",
    "y_pred_G = Model1.predict(X_test)\n",
    "print(f\"The prediction output is {y_pred_G[0:5]}, meanwhile the real output we have is {y_test[0:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 = Entropy Decision Tree Model (Random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=5,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model2 = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 5)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction output is ['drugX' 'drugY' 'drugX' 'drugC' 'drugY'], meanwhile the real output we have is ['drugX' 'drugY' 'drugX' 'drugC' 'drugY']\n"
     ]
    }
   ],
   "source": [
    "Model2.fit(X_train, y_train)\n",
    "y_pred_E = Model2.predict(X_test)\n",
    "print(f\"The prediction output is {y_pred_E[0:5]}, meanwhile the real output we have is {y_test[0:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation using accuracy and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Gini = 0.9666666666666667 & Accuracy for Entropy = 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc1 = accuracy_score(y_test, y_pred_G)\n",
    "acc2 = accuracy_score(y_test, y_pred_E)\n",
    "print(f\"Accuracy for Gini = {acc1} & Accuracy for Entropy = {acc2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.67      1.00      0.80         4\n",
      "       drugB       1.00      0.67      0.80         6\n",
      "       drugC       1.00      1.00      1.00         4\n",
      "       drugX       1.00      1.00      1.00        19\n",
      "       drugY       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           0.97        60\n",
      "   macro avg       0.93      0.93      0.92        60\n",
      "weighted avg       0.98      0.97      0.97        60\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.67      1.00      0.80         4\n",
      "       drugB       1.00      0.67      0.80         6\n",
      "       drugC       1.00      1.00      1.00         4\n",
      "       drugX       1.00      1.00      1.00        19\n",
      "       drugY       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           0.97        60\n",
      "   macro avg       0.93      0.93      0.92        60\n",
      "weighted avg       0.98      0.97      0.97        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cls_report1 = classification_report(y_test, y_pred_G)\n",
    "cls_report2 = classification_report(y_test, y_pred_E)\n",
    "\n",
    "print(f\"{cls_report1}\")\n",
    "print(f\"{cls_report2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  0  0  0]\n",
      " [ 2  4  0  0  0]\n",
      " [ 0  0  4  0  0]\n",
      " [ 0  0  0 19  0]\n",
      " [ 0  0  0  0 27]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred_G)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project decision tree model (model1 & model2) yield similar result. \n",
    "\n",
    "In theory, Entropy would yield better result due to its complexity. Whereas, Gini impurity is also pretty accurate with less latency due to straight forward split method (simpler computation).\n",
    "\n",
    "__First Result: Gini and Entropy yield same result. Factors could be because our data only consist 200 data (pharmacy).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, I found out that if we change the random_state in our decision tree model we can get better prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 = Decision Tree Model (Random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since both Gini and Entropy yield same accuracy so we choose one here\n",
    "Model = DecisionTreeClassifier(criterion=\"gini\", max_depth = 4)\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction output is ['drugY' 'drugX' 'drugX' 'drugX' 'drugX'], meanwhile the real output we have is ['drugY' 'drugX' 'drugX' 'drugX' 'drugX']\n"
     ]
    }
   ],
   "source": [
    "Model.fit(X_train, y_train)\n",
    "y_pred_new = Model.predict(X_test)\n",
    "print(f\"The prediction output is {y_pred_new[0:5]}, meanwhile the real output we have is {y_test[0:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Gini = 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "acc1 = accuracy_score(y_test, y_pred_new)\n",
    "print(f\"Accuracy for Gini = {acc1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       1.00      1.00      1.00         7\n",
      "       drugB       1.00      1.00      1.00         5\n",
      "       drugC       1.00      1.00      1.00         5\n",
      "       drugX       1.00      0.95      0.98        21\n",
      "       drugY       0.96      1.00      0.98        22\n",
      "\n",
      "    accuracy                           0.98        60\n",
      "   macro avg       0.99      0.99      0.99        60\n",
      "weighted avg       0.98      0.98      0.98        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = classification_report(y_test, y_pred_new)\n",
    "\n",
    "print(f\"{cls_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  0  0  0  0]\n",
      " [ 0  5  0  0  0]\n",
      " [ 0  0  5  0  0]\n",
      " [ 0  0  0 20  1]\n",
      " [ 0  0  0  0 22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm = confusion_matrix(y_test, y_pred_new)\n",
    "print(cfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the random state (1 to 3) increase the f1-score accuracy by 0.01 (0.97 to 0.98)\n",
    "\n",
    "The confusion matrix also explains positive correlation of this model.\n",
    "\n",
    "__Second result: Using the 'Decision Tree Model' with different 'random_state', by increasing randomness in data we can obtain better accuracy.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, I want to model it using Random Forest, which normally will yiel better accuracy rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 = Random Forest Model (Random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['drugX', 'drugY', 'drugX', 'drugC', 'drugY', 'drugX', 'drugX',\n",
       "       'drugY', 'drugY', 'drugY', 'drugX', 'drugC', 'drugY', 'drugY',\n",
       "       'drugA', 'drugA', 'drugX', 'drugX', 'drugB', 'drugY', 'drugX',\n",
       "       'drugX', 'drugX', 'drugY', 'drugB', 'drugX', 'drugX', 'drugY',\n",
       "       'drugX', 'drugX', 'drugC', 'drugY', 'drugY', 'drugY', 'drugA',\n",
       "       'drugY', 'drugA', 'drugY', 'drugY', 'drugY', 'drugB', 'drugY',\n",
       "       'drugY', 'drugX', 'drugB', 'drugY', 'drugX', 'drugX', 'drugY',\n",
       "       'drugA', 'drugY', 'drugY', 'drugY', 'drugY', 'drugY', 'drugY',\n",
       "       'drugX', 'drugX', 'drugX', 'drugA'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rand_forest = RandomForestClassifier(n_estimators=200)\n",
    "rand_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Gini = 0.95\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy for Gini = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.67      1.00      0.80         4\n",
      "       drugB       1.00      0.67      0.80         6\n",
      "       drugC       1.00      0.75      0.86         4\n",
      "       drugX       0.95      1.00      0.97        19\n",
      "       drugY       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           0.95        60\n",
      "   macro avg       0.92      0.88      0.89        60\n",
      "weighted avg       0.96      0.95      0.95        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"{cls_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Third result: In this case, the random forest gives less accuracy compare to decision tree model, this could possibly cause underfitting.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas normally __'Random Forest model'__ will give much better accuracy than __'Decision Tree model'__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So we can try use __cross validation method (K-fold Library)__ and check the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 : Cross-Validation on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  0  0  0]\n",
      " [ 2  4  0  0  0]\n",
      " [ 0  0  3  1  0]\n",
      " [ 0  0  0 19  0]\n",
      " [ 0  0  0  0 27]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm = confusion_matrix(y_test, y_pred)\n",
    "print(cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [[23 0 0 0 25.355]\n",
      " [47 1 1 0 13.093]\n",
      " [47 1 1 0 10.113999999999999]\n",
      " [28 0 2 0 7.797999999999999]\n",
      " [22 0 2 0 8.607000000000001]\n",
      " [49 0 2 0 16.275]\n",
      " [41 1 1 0 11.037]\n",
      " [60 1 2 0 15.171]\n",
      " [43 1 1 1 19.368]\n",
      " [47 0 1 0 11.767000000000001]\n",
      " [43 1 1 0 15.376]\n",
      " [74 0 1 0 20.941999999999997]\n",
      " [50 0 2 0 12.703]\n",
      " [16 0 0 1 15.515999999999998]\n",
      " [69 1 1 1 11.455]\n",
      " [43 1 0 0 13.972000000000001]\n",
      " [32 0 0 1 25.974]\n",
      " [57 1 1 1 19.128]\n",
      " [63 1 2 0 25.916999999999998]\n",
      " [47 1 1 1 30.568]\n",
      " [48 0 1 0 15.036]\n",
      " [33 0 1 0 33.486]\n",
      " [28 0 0 1 18.809]\n",
      " [31 1 0 0 30.366]\n",
      " [49 0 2 1 9.381]\n",
      " [39 0 1 1 22.697]\n",
      " [18 0 2 1 8.75]\n",
      " [74 1 0 0 9.567]\n",
      " [49 1 1 1 11.014000000000001]\n",
      " [65 0 0 1 31.875999999999998]\n",
      " [32 1 0 1 9.445]\n",
      " [39 1 1 1 13.937999999999999]\n",
      " [39 0 2 1 9.709]\n",
      " [15 1 2 0 9.084]\n",
      " [58 0 0 1 14.239]\n",
      " [50 1 2 1 15.79]\n",
      " [23 1 2 0 12.26]\n",
      " [50 0 2 1 12.295]\n",
      " [66 0 2 1 8.107000000000001]\n",
      " [37 0 0 0 13.091]\n",
      " [68 1 1 0 10.290999999999999]\n",
      " [23 1 2 0 31.686]\n",
      " [28 0 1 0 19.796]\n",
      " [58 0 0 0 19.416]\n",
      " [67 1 2 1 10.898]\n",
      " [62 1 1 1 27.183000000000003]\n",
      " [24 0 0 1 18.457]\n",
      " [68 0 0 1 10.189]\n",
      " [26 0 1 0 14.16]\n",
      " [65 1 0 1 11.34]\n",
      " [40 1 0 0 27.826]\n",
      " [38 0 1 1 29.875]\n",
      " [24 1 0 1 9.475]\n",
      " [67 1 1 1 20.693]\n",
      " [45 1 1 1 8.37]\n",
      " [60 0 0 0 13.302999999999999]\n",
      " [68 0 2 1 27.05]\n",
      " [29 1 0 0 12.856]\n",
      " [17 1 2 1 10.832]\n",
      " [54 1 2 0 24.658]\n",
      " [18 0 0 1 24.276]\n",
      " [70 1 0 0 13.967]\n",
      " [28 0 2 0 19.675]\n",
      " [24 0 2 0 10.605]\n",
      " [41 0 2 1 22.905]\n",
      " [31 1 0 1 17.069000000000003]\n",
      " [26 1 1 1 20.909000000000002]\n",
      " [36 0 0 0 11.198]\n",
      " [26 0 0 1 19.160999999999998]\n",
      " [19 0 0 0 13.312999999999999]\n",
      " [32 0 1 1 10.84]\n",
      " [60 1 0 0 13.934000000000001]\n",
      " [64 1 2 0 7.761]\n",
      " [32 0 1 0 9.712]\n",
      " [38 0 0 1 11.325999999999999]\n",
      " [47 0 1 0 10.067]\n",
      " [59 1 0 0 13.935]\n",
      " [51 0 2 0 13.597000000000001]\n",
      " [69 1 1 0 15.478]\n",
      " [37 0 0 1 23.090999999999998]\n",
      " [62 1 2 0 16.594]\n",
      " [41 1 0 1 15.155999999999999]\n",
      " [29 0 0 0 29.45]\n",
      " [42 0 1 1 29.271]\n",
      " [56 1 1 0 15.015]\n",
      " [58 0 1 0 38.247]\n",
      " [56 0 0 0 25.395]\n",
      " [20 1 0 1 35.639]\n",
      " [15 0 0 1 16.725]\n",
      " [31 1 0 1 11.870999999999999]\n",
      " [45 0 0 0 12.854000000000001]\n",
      " [56 1 2 0 8.966000000000001]\n",
      " [22 1 0 1 28.294]\n",
      " [37 1 1 1 8.968]\n",
      " [22 1 2 0 11.953]\n",
      " [42 1 1 0 20.012999999999998]\n",
      " [72 1 0 1 9.677]\n",
      " [23 1 2 0 16.85]\n",
      " [47 0 2 1 6.683]\n",
      " [35 1 1 1 9.17]\n",
      " [65 0 1 1 13.769]\n",
      " [20 0 2 1 9.281]\n",
      " [51 1 0 0 18.295]\n",
      " [67 1 2 1 9.514]\n",
      " [40 0 2 0 10.103]\n",
      " [61 0 0 0 25.475]\n",
      " [28 1 2 0 27.064]\n",
      " [15 1 0 1 17.206]\n",
      " [34 1 2 0 22.456]\n",
      " [36 0 2 0 16.753]\n",
      " [53 0 0 1 12.495]\n",
      " [19 0 0 1 25.969]\n",
      " [66 1 0 0 16.347]\n",
      " [35 1 2 1 7.845]\n",
      " [47 1 1 1 33.542]\n",
      " [32 0 2 0 7.477]\n",
      " [70 0 2 0 20.489]\n",
      " [52 1 1 1 32.922]\n",
      " [49 1 1 1 13.597999999999999]\n",
      " [24 1 2 0 25.785999999999998]\n",
      " [42 0 0 0 21.035999999999998]\n",
      " [74 1 1 1 11.939]\n",
      " [35 0 0 0 12.894]\n",
      " [51 1 0 1 11.343]\n",
      " [69 0 2 0 10.065]\n",
      " [49 1 0 1 6.269]\n",
      " [64 0 1 1 25.741]\n",
      " [60 1 0 1 8.621]\n",
      " [74 1 0 1 15.436]\n",
      " [39 1 0 0 9.664]\n",
      " [61 1 2 0 9.443]\n",
      " [37 0 1 1 12.005999999999998]\n",
      " [26 0 0 1 12.307]\n",
      " [61 0 1 1 7.34]\n",
      " [22 1 1 0 8.151]\n",
      " [49 1 0 1 8.7]\n",
      " [68 1 0 0 11.009]\n",
      " [55 1 2 1 7.261]\n",
      " [72 0 1 1 14.642000000000001]\n",
      " [37 1 1 1 16.724]\n",
      " [49 1 1 0 10.537]\n",
      " [31 1 0 1 11.227]\n",
      " [53 1 1 0 22.963]\n",
      " [59 0 1 0 10.444]\n",
      " [30 0 2 0 10.443]\n",
      " [57 0 0 1 9.945]\n",
      " [43 1 2 1 12.859000000000002]\n",
      " [21 0 0 1 28.631999999999998]\n",
      " [16 1 0 1 19.007]\n",
      " [38 1 1 0 18.295]\n",
      " [58 0 1 0 26.645]\n",
      " [57 0 2 0 14.216]\n",
      " [20 0 0 0 11.262]\n",
      " [28 0 2 0 12.879000000000001]\n",
      " [39 0 2 1 17.225]\n",
      " [41 0 1 1 18.739]\n",
      " [42 1 0 1 12.765999999999998]\n",
      " [73 0 0 0 18.348]\n",
      " [48 1 0 1 10.446]\n",
      " [25 1 2 0 19.011]\n",
      " [39 1 2 0 15.969000000000001]\n",
      " [67 0 2 0 15.890999999999998]\n",
      " [22 0 0 1 22.818]\n",
      " [59 0 2 0 13.884]\n",
      " [20 0 1 1 11.686]\n",
      " [36 0 0 1 15.49]\n",
      " [57 0 2 1 25.893]\n",
      " [70 1 0 0 9.849]\n",
      " [47 1 0 0 10.402999999999999]\n",
      " [65 1 0 1 34.997]\n",
      " [64 1 0 1 20.932]\n",
      " [58 1 0 0 18.991]\n",
      " [23 1 0 0 8.011000000000001]\n",
      " [72 1 1 0 16.31]\n",
      " [72 1 1 0 6.769]\n",
      " [46 0 0 0 34.686]\n",
      " [56 0 1 0 11.567]\n",
      " [16 1 1 0 12.005999999999998]\n",
      " [52 1 2 0 9.894]\n",
      " [40 0 1 1 11.349]], test: [[61 0 1 0 18.043]\n",
      " [34 0 0 1 19.199]\n",
      " [23 1 1 0 7.297999999999999]\n",
      " [45 1 1 0 17.951]\n",
      " [53 1 2 0 14.133]\n",
      " [46 1 2 1 7.285]\n",
      " [73 0 2 0 19.221]\n",
      " [60 1 2 1 10.091000000000001]\n",
      " [34 1 0 0 18.703]\n",
      " [50 0 2 1 17.211]\n",
      " [36 1 1 1 11.424000000000001]\n",
      " [28 0 1 0 13.127]\n",
      " [50 1 0 0 7.49]\n",
      " [32 0 0 1 10.292]\n",
      " [55 0 0 0 10.977]\n",
      " [34 0 1 1 12.923]\n",
      " [51 0 1 1 23.003]\n",
      " [45 1 1 1 10.017000000000001]\n",
      " [18 0 0 0 37.188]\n",
      " [23 1 2 1 14.02]]\n",
      "train: [[23 0 0 0 25.355]\n",
      " [47 1 1 0 13.093]\n",
      " [47 1 1 0 10.113999999999999]\n",
      " [28 0 2 0 7.797999999999999]\n",
      " [61 0 1 0 18.043]\n",
      " [22 0 2 0 8.607000000000001]\n",
      " [49 0 2 0 16.275]\n",
      " [41 1 1 0 11.037]\n",
      " [60 1 2 0 15.171]\n",
      " [43 1 1 1 19.368]\n",
      " [47 0 1 0 11.767000000000001]\n",
      " [34 0 0 1 19.199]\n",
      " [43 1 1 0 15.376]\n",
      " [74 0 1 0 20.941999999999997]\n",
      " [50 0 2 0 12.703]\n",
      " [16 0 0 1 15.515999999999998]\n",
      " [43 1 0 0 13.972000000000001]\n",
      " [23 1 1 0 7.297999999999999]\n",
      " [32 0 0 1 25.974]\n",
      " [57 1 1 1 19.128]\n",
      " [63 1 2 0 25.916999999999998]\n",
      " [47 1 1 1 30.568]\n",
      " [48 0 1 0 15.036]\n",
      " [33 0 1 0 33.486]\n",
      " [28 0 0 1 18.809]\n",
      " [31 1 0 0 30.366]\n",
      " [45 1 1 0 17.951]\n",
      " [18 0 2 1 8.75]\n",
      " [49 1 1 1 11.014000000000001]\n",
      " [65 0 0 1 31.875999999999998]\n",
      " [53 1 2 0 14.133]\n",
      " [46 1 2 1 7.285]\n",
      " [32 1 0 1 9.445]\n",
      " [39 1 1 1 13.937999999999999]\n",
      " [15 1 2 0 9.084]\n",
      " [73 0 2 0 19.221]\n",
      " [58 0 0 1 14.239]\n",
      " [50 1 2 1 15.79]\n",
      " [23 1 2 0 12.26]\n",
      " [66 0 2 1 8.107000000000001]\n",
      " [37 0 0 0 13.091]\n",
      " [23 1 2 0 31.686]\n",
      " [28 0 1 0 19.796]\n",
      " [58 0 0 0 19.416]\n",
      " [62 1 1 1 27.183000000000003]\n",
      " [24 0 0 1 18.457]\n",
      " [68 0 0 1 10.189]\n",
      " [26 0 1 0 14.16]\n",
      " [65 1 0 1 11.34]\n",
      " [40 1 0 0 27.826]\n",
      " [60 1 2 1 10.091000000000001]\n",
      " [34 1 0 0 18.703]\n",
      " [38 0 1 1 29.875]\n",
      " [24 1 0 1 9.475]\n",
      " [67 1 1 1 20.693]\n",
      " [45 1 1 1 8.37]\n",
      " [60 0 0 0 13.302999999999999]\n",
      " [68 0 2 1 27.05]\n",
      " [29 1 0 0 12.856]\n",
      " [17 1 2 1 10.832]\n",
      " [54 1 2 0 24.658]\n",
      " [70 1 0 0 13.967]\n",
      " [28 0 2 0 19.675]\n",
      " [24 0 2 0 10.605]\n",
      " [31 1 0 1 17.069000000000003]\n",
      " [26 1 1 1 20.909000000000002]\n",
      " [36 0 0 0 11.198]\n",
      " [26 0 0 1 19.160999999999998]\n",
      " [19 0 0 0 13.312999999999999]\n",
      " [32 0 1 1 10.84]\n",
      " [60 1 0 0 13.934000000000001]\n",
      " [64 1 2 0 7.761]\n",
      " [32 0 1 0 9.712]\n",
      " [38 0 0 1 11.325999999999999]\n",
      " [47 0 1 0 10.067]\n",
      " [59 1 0 0 13.935]\n",
      " [51 0 2 0 13.597000000000001]\n",
      " [69 1 1 0 15.478]\n",
      " [37 0 0 1 23.090999999999998]\n",
      " [50 0 2 1 17.211]\n",
      " [62 1 2 0 16.594]\n",
      " [41 1 0 1 15.155999999999999]\n",
      " [29 0 0 0 29.45]\n",
      " [42 0 1 1 29.271]\n",
      " [36 1 1 1 11.424000000000001]\n",
      " [58 0 1 0 38.247]\n",
      " [20 1 0 1 35.639]\n",
      " [15 0 0 1 16.725]\n",
      " [31 1 0 1 11.870999999999999]\n",
      " [45 0 0 0 12.854000000000001]\n",
      " [28 0 1 0 13.127]\n",
      " [56 1 2 0 8.966000000000001]\n",
      " [22 1 0 1 28.294]\n",
      " [37 1 1 1 8.968]\n",
      " [22 1 2 0 11.953]\n",
      " [42 1 1 0 20.012999999999998]\n",
      " [72 1 0 1 9.677]\n",
      " [23 1 2 0 16.85]\n",
      " [50 1 0 0 7.49]\n",
      " [47 0 2 1 6.683]\n",
      " [35 1 1 1 9.17]\n",
      " [65 0 1 1 13.769]\n",
      " [20 0 2 1 9.281]\n",
      " [51 1 0 0 18.295]\n",
      " [67 1 2 1 9.514]\n",
      " [40 0 2 0 10.103]\n",
      " [32 0 0 1 10.292]\n",
      " [61 0 0 0 25.475]\n",
      " [28 1 2 0 27.064]\n",
      " [15 1 0 1 17.206]\n",
      " [34 1 2 0 22.456]\n",
      " [36 0 2 0 16.753]\n",
      " [53 0 0 1 12.495]\n",
      " [19 0 0 1 25.969]\n",
      " [66 1 0 0 16.347]\n",
      " [35 1 2 1 7.845]\n",
      " [47 1 1 1 33.542]\n",
      " [32 0 2 0 7.477]\n",
      " [70 0 2 0 20.489]\n",
      " [52 1 1 1 32.922]\n",
      " [49 1 1 1 13.597999999999999]\n",
      " [24 1 2 0 25.785999999999998]\n",
      " [42 0 0 0 21.035999999999998]\n",
      " [74 1 1 1 11.939]\n",
      " [55 0 0 0 10.977]\n",
      " [35 0 0 0 12.894]\n",
      " [51 1 0 1 11.343]\n",
      " [69 0 2 0 10.065]\n",
      " [49 1 0 1 6.269]\n",
      " [64 0 1 1 25.741]\n",
      " [60 1 0 1 8.621]\n",
      " [74 1 0 1 15.436]\n",
      " [39 1 0 0 9.664]\n",
      " [61 1 2 0 9.443]\n",
      " [37 0 1 1 12.005999999999998]\n",
      " [26 0 0 1 12.307]\n",
      " [61 0 1 1 7.34]\n",
      " [22 1 1 0 8.151]\n",
      " [49 1 0 1 8.7]\n",
      " [68 1 0 0 11.009]\n",
      " [55 1 2 1 7.261]\n",
      " [72 0 1 1 14.642000000000001]\n",
      " [37 1 1 1 16.724]\n",
      " [49 1 1 0 10.537]\n",
      " [31 1 0 1 11.227]\n",
      " [53 1 1 0 22.963]\n",
      " [59 0 1 0 10.444]\n",
      " [34 0 1 1 12.923]\n",
      " [30 0 2 0 10.443]\n",
      " [57 0 0 1 9.945]\n",
      " [21 0 0 1 28.631999999999998]\n",
      " [16 1 0 1 19.007]\n",
      " [58 0 1 0 26.645]\n",
      " [57 0 2 0 14.216]\n",
      " [51 0 1 1 23.003]\n",
      " [20 0 0 0 11.262]\n",
      " [28 0 2 0 12.879000000000001]\n",
      " [45 1 1 1 10.017000000000001]\n",
      " [41 0 1 1 18.739]\n",
      " [73 0 0 0 18.348]\n",
      " [39 1 2 0 15.969000000000001]\n",
      " [67 0 2 0 15.890999999999998]\n",
      " [22 0 0 1 22.818]\n",
      " [59 0 2 0 13.884]\n",
      " [20 0 1 1 11.686]\n",
      " [36 0 0 1 15.49]\n",
      " [18 0 0 0 37.188]\n",
      " [57 0 2 1 25.893]\n",
      " [70 1 0 0 9.849]\n",
      " [47 1 0 0 10.402999999999999]\n",
      " [65 1 0 1 34.997]\n",
      " [64 1 0 1 20.932]\n",
      " [58 1 0 0 18.991]\n",
      " [23 1 0 0 8.011000000000001]\n",
      " [72 1 1 0 16.31]\n",
      " [56 0 1 0 11.567]\n",
      " [16 1 1 0 12.005999999999998]\n",
      " [52 1 2 0 9.894]\n",
      " [23 1 2 1 14.02]\n",
      " [40 0 1 1 11.349]], test: [[69 1 1 1 11.455]\n",
      " [49 0 2 1 9.381]\n",
      " [39 0 1 1 22.697]\n",
      " [74 1 0 0 9.567]\n",
      " [39 0 2 1 9.709]\n",
      " [50 0 2 1 12.295]\n",
      " [68 1 1 0 10.290999999999999]\n",
      " [67 1 2 1 10.898]\n",
      " [18 0 0 1 24.276]\n",
      " [41 0 2 1 22.905]\n",
      " [56 1 1 0 15.015]\n",
      " [56 0 0 0 25.395]\n",
      " [43 1 2 1 12.859000000000002]\n",
      " [38 1 1 0 18.295]\n",
      " [39 0 2 1 17.225]\n",
      " [42 1 0 1 12.765999999999998]\n",
      " [48 1 0 1 10.446]\n",
      " [25 1 2 0 19.011]\n",
      " [72 1 1 0 6.769]\n",
      " [46 0 0 0 34.686]]\n",
      "train: [[23 0 0 0 25.355]\n",
      " [47 1 1 0 13.093]\n",
      " [47 1 1 0 10.113999999999999]\n",
      " [28 0 2 0 7.797999999999999]\n",
      " [61 0 1 0 18.043]\n",
      " [22 0 2 0 8.607000000000001]\n",
      " [49 0 2 0 16.275]\n",
      " [41 1 1 0 11.037]\n",
      " [60 1 2 0 15.171]\n",
      " [43 1 1 1 19.368]\n",
      " [47 0 1 0 11.767000000000001]\n",
      " [34 0 0 1 19.199]\n",
      " [43 1 1 0 15.376]\n",
      " [74 0 1 0 20.941999999999997]\n",
      " [16 0 0 1 15.515999999999998]\n",
      " [69 1 1 1 11.455]\n",
      " [43 1 0 0 13.972000000000001]\n",
      " [23 1 1 0 7.297999999999999]\n",
      " [57 1 1 1 19.128]\n",
      " [63 1 2 0 25.916999999999998]\n",
      " [47 1 1 1 30.568]\n",
      " [48 0 1 0 15.036]\n",
      " [33 0 1 0 33.486]\n",
      " [28 0 0 1 18.809]\n",
      " [31 1 0 0 30.366]\n",
      " [49 0 2 1 9.381]\n",
      " [39 0 1 1 22.697]\n",
      " [45 1 1 0 17.951]\n",
      " [18 0 2 1 8.75]\n",
      " [74 1 0 0 9.567]\n",
      " [49 1 1 1 11.014000000000001]\n",
      " [53 1 2 0 14.133]\n",
      " [46 1 2 1 7.285]\n",
      " [32 1 0 1 9.445]\n",
      " [39 1 1 1 13.937999999999999]\n",
      " [39 0 2 1 9.709]\n",
      " [73 0 2 0 19.221]\n",
      " [58 0 0 1 14.239]\n",
      " [50 1 2 1 15.79]\n",
      " [23 1 2 0 12.26]\n",
      " [50 0 2 1 12.295]\n",
      " [66 0 2 1 8.107000000000001]\n",
      " [37 0 0 0 13.091]\n",
      " [68 1 1 0 10.290999999999999]\n",
      " [23 1 2 0 31.686]\n",
      " [28 0 1 0 19.796]\n",
      " [58 0 0 0 19.416]\n",
      " [67 1 2 1 10.898]\n",
      " [62 1 1 1 27.183000000000003]\n",
      " [68 0 0 1 10.189]\n",
      " [26 0 1 0 14.16]\n",
      " [40 1 0 0 27.826]\n",
      " [60 1 2 1 10.091000000000001]\n",
      " [34 1 0 0 18.703]\n",
      " [38 0 1 1 29.875]\n",
      " [24 1 0 1 9.475]\n",
      " [67 1 1 1 20.693]\n",
      " [45 1 1 1 8.37]\n",
      " [60 0 0 0 13.302999999999999]\n",
      " [68 0 2 1 27.05]\n",
      " [29 1 0 0 12.856]\n",
      " [17 1 2 1 10.832]\n",
      " [54 1 2 0 24.658]\n",
      " [18 0 0 1 24.276]\n",
      " [70 1 0 0 13.967]\n",
      " [28 0 2 0 19.675]\n",
      " [24 0 2 0 10.605]\n",
      " [41 0 2 1 22.905]\n",
      " [31 1 0 1 17.069000000000003]\n",
      " [26 1 1 1 20.909000000000002]\n",
      " [36 0 0 0 11.198]\n",
      " [26 0 0 1 19.160999999999998]\n",
      " [19 0 0 0 13.312999999999999]\n",
      " [32 0 1 1 10.84]\n",
      " [60 1 0 0 13.934000000000001]\n",
      " [64 1 2 0 7.761]\n",
      " [32 0 1 0 9.712]\n",
      " [38 0 0 1 11.325999999999999]\n",
      " [47 0 1 0 10.067]\n",
      " [59 1 0 0 13.935]\n",
      " [51 0 2 0 13.597000000000001]\n",
      " [69 1 1 0 15.478]\n",
      " [37 0 0 1 23.090999999999998]\n",
      " [50 0 2 1 17.211]\n",
      " [62 1 2 0 16.594]\n",
      " [41 1 0 1 15.155999999999999]\n",
      " [29 0 0 0 29.45]\n",
      " [42 0 1 1 29.271]\n",
      " [56 1 1 0 15.015]\n",
      " [36 1 1 1 11.424000000000001]\n",
      " [58 0 1 0 38.247]\n",
      " [56 0 0 0 25.395]\n",
      " [15 0 0 1 16.725]\n",
      " [31 1 0 1 11.870999999999999]\n",
      " [45 0 0 0 12.854000000000001]\n",
      " [28 0 1 0 13.127]\n",
      " [56 1 2 0 8.966000000000001]\n",
      " [22 1 0 1 28.294]\n",
      " [37 1 1 1 8.968]\n",
      " [23 1 2 0 16.85]\n",
      " [50 1 0 0 7.49]\n",
      " [47 0 2 1 6.683]\n",
      " [35 1 1 1 9.17]\n",
      " [65 0 1 1 13.769]\n",
      " [51 1 0 0 18.295]\n",
      " [67 1 2 1 9.514]\n",
      " [40 0 2 0 10.103]\n",
      " [32 0 0 1 10.292]\n",
      " [28 1 2 0 27.064]\n",
      " [15 1 0 1 17.206]\n",
      " [34 1 2 0 22.456]\n",
      " [19 0 0 1 25.969]\n",
      " [66 1 0 0 16.347]\n",
      " [35 1 2 1 7.845]\n",
      " [47 1 1 1 33.542]\n",
      " [32 0 2 0 7.477]\n",
      " [70 0 2 0 20.489]\n",
      " [52 1 1 1 32.922]\n",
      " [49 1 1 1 13.597999999999999]\n",
      " [24 1 2 0 25.785999999999998]\n",
      " [42 0 0 0 21.035999999999998]\n",
      " [74 1 1 1 11.939]\n",
      " [55 0 0 0 10.977]\n",
      " [35 0 0 0 12.894]\n",
      " [69 0 2 0 10.065]\n",
      " [49 1 0 1 6.269]\n",
      " [64 0 1 1 25.741]\n",
      " [60 1 0 1 8.621]\n",
      " [74 1 0 1 15.436]\n",
      " [39 1 0 0 9.664]\n",
      " [61 1 2 0 9.443]\n",
      " [37 0 1 1 12.005999999999998]\n",
      " [26 0 0 1 12.307]\n",
      " [61 0 1 1 7.34]\n",
      " [22 1 1 0 8.151]\n",
      " [49 1 0 1 8.7]\n",
      " [68 1 0 0 11.009]\n",
      " [55 1 2 1 7.261]\n",
      " [72 0 1 1 14.642000000000001]\n",
      " [37 1 1 1 16.724]\n",
      " [49 1 1 0 10.537]\n",
      " [31 1 0 1 11.227]\n",
      " [53 1 1 0 22.963]\n",
      " [59 0 1 0 10.444]\n",
      " [34 0 1 1 12.923]\n",
      " [30 0 2 0 10.443]\n",
      " [57 0 0 1 9.945]\n",
      " [43 1 2 1 12.859000000000002]\n",
      " [21 0 0 1 28.631999999999998]\n",
      " [16 1 0 1 19.007]\n",
      " [38 1 1 0 18.295]\n",
      " [58 0 1 0 26.645]\n",
      " [57 0 2 0 14.216]\n",
      " [51 0 1 1 23.003]\n",
      " [20 0 0 0 11.262]\n",
      " [28 0 2 0 12.879000000000001]\n",
      " [45 1 1 1 10.017000000000001]\n",
      " [39 0 2 1 17.225]\n",
      " [41 0 1 1 18.739]\n",
      " [42 1 0 1 12.765999999999998]\n",
      " [73 0 0 0 18.348]\n",
      " [48 1 0 1 10.446]\n",
      " [25 1 2 0 19.011]\n",
      " [39 1 2 0 15.969000000000001]\n",
      " [22 0 0 1 22.818]\n",
      " [20 0 1 1 11.686]\n",
      " [36 0 0 1 15.49]\n",
      " [18 0 0 0 37.188]\n",
      " [70 1 0 0 9.849]\n",
      " [47 1 0 0 10.402999999999999]\n",
      " [65 1 0 1 34.997]\n",
      " [58 1 0 0 18.991]\n",
      " [23 1 0 0 8.011000000000001]\n",
      " [72 1 1 0 16.31]\n",
      " [72 1 1 0 6.769]\n",
      " [46 0 0 0 34.686]\n",
      " [56 0 1 0 11.567]\n",
      " [16 1 1 0 12.005999999999998]\n",
      " [52 1 2 0 9.894]\n",
      " [23 1 2 1 14.02]], test: [[50 0 2 0 12.703]\n",
      " [32 0 0 1 25.974]\n",
      " [65 0 0 1 31.875999999999998]\n",
      " [15 1 2 0 9.084]\n",
      " [24 0 0 1 18.457]\n",
      " [65 1 0 1 11.34]\n",
      " [20 1 0 1 35.639]\n",
      " [22 1 2 0 11.953]\n",
      " [42 1 1 0 20.012999999999998]\n",
      " [72 1 0 1 9.677]\n",
      " [20 0 2 1 9.281]\n",
      " [61 0 0 0 25.475]\n",
      " [36 0 2 0 16.753]\n",
      " [53 0 0 1 12.495]\n",
      " [51 1 0 1 11.343]\n",
      " [67 0 2 0 15.890999999999998]\n",
      " [59 0 2 0 13.884]\n",
      " [57 0 2 1 25.893]\n",
      " [64 1 0 1 20.932]\n",
      " [40 0 1 1 11.349]]\n",
      "train: [[23 0 0 0 25.355]\n",
      " [47 1 1 0 13.093]\n",
      " [47 1 1 0 10.113999999999999]\n",
      " [28 0 2 0 7.797999999999999]\n",
      " [61 0 1 0 18.043]\n",
      " [49 0 2 0 16.275]\n",
      " [41 1 1 0 11.037]\n",
      " [60 1 2 0 15.171]\n",
      " [43 1 1 1 19.368]\n",
      " [47 0 1 0 11.767000000000001]\n",
      " [34 0 0 1 19.199]\n",
      " [74 0 1 0 20.941999999999997]\n",
      " [50 0 2 0 12.703]\n",
      " [16 0 0 1 15.515999999999998]\n",
      " [69 1 1 1 11.455]\n",
      " [23 1 1 0 7.297999999999999]\n",
      " [32 0 0 1 25.974]\n",
      " [57 1 1 1 19.128]\n",
      " [63 1 2 0 25.916999999999998]\n",
      " [47 1 1 1 30.568]\n",
      " [48 0 1 0 15.036]\n",
      " [33 0 1 0 33.486]\n",
      " [28 0 0 1 18.809]\n",
      " [31 1 0 0 30.366]\n",
      " [49 0 2 1 9.381]\n",
      " [39 0 1 1 22.697]\n",
      " [45 1 1 0 17.951]\n",
      " [18 0 2 1 8.75]\n",
      " [74 1 0 0 9.567]\n",
      " [49 1 1 1 11.014000000000001]\n",
      " [65 0 0 1 31.875999999999998]\n",
      " [53 1 2 0 14.133]\n",
      " [46 1 2 1 7.285]\n",
      " [32 1 0 1 9.445]\n",
      " [39 1 1 1 13.937999999999999]\n",
      " [39 0 2 1 9.709]\n",
      " [15 1 2 0 9.084]\n",
      " [73 0 2 0 19.221]\n",
      " [58 0 0 1 14.239]\n",
      " [23 1 2 0 12.26]\n",
      " [50 0 2 1 12.295]\n",
      " [66 0 2 1 8.107000000000001]\n",
      " [37 0 0 0 13.091]\n",
      " [68 1 1 0 10.290999999999999]\n",
      " [28 0 1 0 19.796]\n",
      " [58 0 0 0 19.416]\n",
      " [67 1 2 1 10.898]\n",
      " [62 1 1 1 27.183000000000003]\n",
      " [24 0 0 1 18.457]\n",
      " [26 0 1 0 14.16]\n",
      " [65 1 0 1 11.34]\n",
      " [40 1 0 0 27.826]\n",
      " [60 1 2 1 10.091000000000001]\n",
      " [34 1 0 0 18.703]\n",
      " [38 0 1 1 29.875]\n",
      " [24 1 0 1 9.475]\n",
      " [67 1 1 1 20.693]\n",
      " [45 1 1 1 8.37]\n",
      " [60 0 0 0 13.302999999999999]\n",
      " [68 0 2 1 27.05]\n",
      " [54 1 2 0 24.658]\n",
      " [18 0 0 1 24.276]\n",
      " [70 1 0 0 13.967]\n",
      " [28 0 2 0 19.675]\n",
      " [24 0 2 0 10.605]\n",
      " [41 0 2 1 22.905]\n",
      " [31 1 0 1 17.069000000000003]\n",
      " [26 1 1 1 20.909000000000002]\n",
      " [36 0 0 0 11.198]\n",
      " [26 0 0 1 19.160999999999998]\n",
      " [32 0 1 1 10.84]\n",
      " [60 1 0 0 13.934000000000001]\n",
      " [64 1 2 0 7.761]\n",
      " [32 0 1 0 9.712]\n",
      " [38 0 0 1 11.325999999999999]\n",
      " [59 1 0 0 13.935]\n",
      " [51 0 2 0 13.597000000000001]\n",
      " [69 1 1 0 15.478]\n",
      " [37 0 0 1 23.090999999999998]\n",
      " [50 0 2 1 17.211]\n",
      " [62 1 2 0 16.594]\n",
      " [41 1 0 1 15.155999999999999]\n",
      " [29 0 0 0 29.45]\n",
      " [56 1 1 0 15.015]\n",
      " [36 1 1 1 11.424000000000001]\n",
      " [58 0 1 0 38.247]\n",
      " [56 0 0 0 25.395]\n",
      " [20 1 0 1 35.639]\n",
      " [15 0 0 1 16.725]\n",
      " [31 1 0 1 11.870999999999999]\n",
      " [45 0 0 0 12.854000000000001]\n",
      " [28 0 1 0 13.127]\n",
      " [56 1 2 0 8.966000000000001]\n",
      " [22 1 0 1 28.294]\n",
      " [22 1 2 0 11.953]\n",
      " [42 1 1 0 20.012999999999998]\n",
      " [72 1 0 1 9.677]\n",
      " [23 1 2 0 16.85]\n",
      " [50 1 0 0 7.49]\n",
      " [47 0 2 1 6.683]\n",
      " [35 1 1 1 9.17]\n",
      " [20 0 2 1 9.281]\n",
      " [51 1 0 0 18.295]\n",
      " [32 0 0 1 10.292]\n",
      " [61 0 0 0 25.475]\n",
      " [15 1 0 1 17.206]\n",
      " [34 1 2 0 22.456]\n",
      " [36 0 2 0 16.753]\n",
      " [53 0 0 1 12.495]\n",
      " [19 0 0 1 25.969]\n",
      " [66 1 0 0 16.347]\n",
      " [47 1 1 1 33.542]\n",
      " [32 0 2 0 7.477]\n",
      " [70 0 2 0 20.489]\n",
      " [52 1 1 1 32.922]\n",
      " [49 1 1 1 13.597999999999999]\n",
      " [24 1 2 0 25.785999999999998]\n",
      " [42 0 0 0 21.035999999999998]\n",
      " [74 1 1 1 11.939]\n",
      " [55 0 0 0 10.977]\n",
      " [35 0 0 0 12.894]\n",
      " [51 1 0 1 11.343]\n",
      " [69 0 2 0 10.065]\n",
      " [49 1 0 1 6.269]\n",
      " [64 0 1 1 25.741]\n",
      " [60 1 0 1 8.621]\n",
      " [74 1 0 1 15.436]\n",
      " [39 1 0 0 9.664]\n",
      " [61 1 2 0 9.443]\n",
      " [37 0 1 1 12.005999999999998]\n",
      " [26 0 0 1 12.307]\n",
      " [61 0 1 1 7.34]\n",
      " [22 1 1 0 8.151]\n",
      " [49 1 0 1 8.7]\n",
      " [68 1 0 0 11.009]\n",
      " [55 1 2 1 7.261]\n",
      " [72 0 1 1 14.642000000000001]\n",
      " [37 1 1 1 16.724]\n",
      " [49 1 1 0 10.537]\n",
      " [31 1 0 1 11.227]\n",
      " [53 1 1 0 22.963]\n",
      " [34 0 1 1 12.923]\n",
      " [30 0 2 0 10.443]\n",
      " [57 0 0 1 9.945]\n",
      " [43 1 2 1 12.859000000000002]\n",
      " [21 0 0 1 28.631999999999998]\n",
      " [16 1 0 1 19.007]\n",
      " [38 1 1 0 18.295]\n",
      " [57 0 2 0 14.216]\n",
      " [51 0 1 1 23.003]\n",
      " [20 0 0 0 11.262]\n",
      " [28 0 2 0 12.879000000000001]\n",
      " [45 1 1 1 10.017000000000001]\n",
      " [39 0 2 1 17.225]\n",
      " [41 0 1 1 18.739]\n",
      " [42 1 0 1 12.765999999999998]\n",
      " [73 0 0 0 18.348]\n",
      " [48 1 0 1 10.446]\n",
      " [25 1 2 0 19.011]\n",
      " [39 1 2 0 15.969000000000001]\n",
      " [67 0 2 0 15.890999999999998]\n",
      " [22 0 0 1 22.818]\n",
      " [59 0 2 0 13.884]\n",
      " [20 0 1 1 11.686]\n",
      " [18 0 0 0 37.188]\n",
      " [57 0 2 1 25.893]\n",
      " [70 1 0 0 9.849]\n",
      " [47 1 0 0 10.402999999999999]\n",
      " [65 1 0 1 34.997]\n",
      " [64 1 0 1 20.932]\n",
      " [58 1 0 0 18.991]\n",
      " [23 1 0 0 8.011000000000001]\n",
      " [72 1 1 0 16.31]\n",
      " [72 1 1 0 6.769]\n",
      " [46 0 0 0 34.686]\n",
      " [56 0 1 0 11.567]\n",
      " [16 1 1 0 12.005999999999998]\n",
      " [52 1 2 0 9.894]\n",
      " [23 1 2 1 14.02]\n",
      " [40 0 1 1 11.349]], test: [[22 0 2 0 8.607000000000001]\n",
      " [43 1 1 0 15.376]\n",
      " [43 1 0 0 13.972000000000001]\n",
      " [50 1 2 1 15.79]\n",
      " [23 1 2 0 31.686]\n",
      " [68 0 0 1 10.189]\n",
      " [29 1 0 0 12.856]\n",
      " [17 1 2 1 10.832]\n",
      " [19 0 0 0 13.312999999999999]\n",
      " [47 0 1 0 10.067]\n",
      " [42 0 1 1 29.271]\n",
      " [37 1 1 1 8.968]\n",
      " [65 0 1 1 13.769]\n",
      " [67 1 2 1 9.514]\n",
      " [40 0 2 0 10.103]\n",
      " [28 1 2 0 27.064]\n",
      " [35 1 2 1 7.845]\n",
      " [59 0 1 0 10.444]\n",
      " [58 0 1 0 26.645]\n",
      " [36 0 0 1 15.49]]\n",
      "train: [[23 0 0 0 25.355]\n",
      " [47 1 1 0 13.093]\n",
      " [47 1 1 0 10.113999999999999]\n",
      " [28 0 2 0 7.797999999999999]\n",
      " [61 0 1 0 18.043]\n",
      " [22 0 2 0 8.607000000000001]\n",
      " [49 0 2 0 16.275]\n",
      " [41 1 1 0 11.037]\n",
      " [60 1 2 0 15.171]\n",
      " [43 1 1 1 19.368]\n",
      " [47 0 1 0 11.767000000000001]\n",
      " [34 0 0 1 19.199]\n",
      " [43 1 1 0 15.376]\n",
      " [50 0 2 0 12.703]\n",
      " [16 0 0 1 15.515999999999998]\n",
      " [69 1 1 1 11.455]\n",
      " [43 1 0 0 13.972000000000001]\n",
      " [23 1 1 0 7.297999999999999]\n",
      " [32 0 0 1 25.974]\n",
      " [57 1 1 1 19.128]\n",
      " [63 1 2 0 25.916999999999998]\n",
      " [47 1 1 1 30.568]\n",
      " [48 0 1 0 15.036]\n",
      " [33 0 1 0 33.486]\n",
      " [28 0 0 1 18.809]\n",
      " [31 1 0 0 30.366]\n",
      " [49 0 2 1 9.381]\n",
      " [39 0 1 1 22.697]\n",
      " [45 1 1 0 17.951]\n",
      " [18 0 2 1 8.75]\n",
      " [74 1 0 0 9.567]\n",
      " [49 1 1 1 11.014000000000001]\n",
      " [65 0 0 1 31.875999999999998]\n",
      " [53 1 2 0 14.133]\n",
      " [46 1 2 1 7.285]\n",
      " [39 1 1 1 13.937999999999999]\n",
      " [39 0 2 1 9.709]\n",
      " [15 1 2 0 9.084]\n",
      " [73 0 2 0 19.221]\n",
      " [58 0 0 1 14.239]\n",
      " [50 1 2 1 15.79]\n",
      " [23 1 2 0 12.26]\n",
      " [50 0 2 1 12.295]\n",
      " [37 0 0 0 13.091]\n",
      " [68 1 1 0 10.290999999999999]\n",
      " [23 1 2 0 31.686]\n",
      " [28 0 1 0 19.796]\n",
      " [58 0 0 0 19.416]\n",
      " [67 1 2 1 10.898]\n",
      " [62 1 1 1 27.183000000000003]\n",
      " [24 0 0 1 18.457]\n",
      " [68 0 0 1 10.189]\n",
      " [26 0 1 0 14.16]\n",
      " [65 1 0 1 11.34]\n",
      " [40 1 0 0 27.826]\n",
      " [60 1 2 1 10.091000000000001]\n",
      " [34 1 0 0 18.703]\n",
      " [38 0 1 1 29.875]\n",
      " [24 1 0 1 9.475]\n",
      " [67 1 1 1 20.693]\n",
      " [45 1 1 1 8.37]\n",
      " [60 0 0 0 13.302999999999999]\n",
      " [68 0 2 1 27.05]\n",
      " [29 1 0 0 12.856]\n",
      " [17 1 2 1 10.832]\n",
      " [54 1 2 0 24.658]\n",
      " [18 0 0 1 24.276]\n",
      " [70 1 0 0 13.967]\n",
      " [28 0 2 0 19.675]\n",
      " [24 0 2 0 10.605]\n",
      " [41 0 2 1 22.905]\n",
      " [31 1 0 1 17.069000000000003]\n",
      " [26 1 1 1 20.909000000000002]\n",
      " [36 0 0 0 11.198]\n",
      " [26 0 0 1 19.160999999999998]\n",
      " [19 0 0 0 13.312999999999999]\n",
      " [32 0 1 1 10.84]\n",
      " [60 1 0 0 13.934000000000001]\n",
      " [38 0 0 1 11.325999999999999]\n",
      " [47 0 1 0 10.067]\n",
      " [59 1 0 0 13.935]\n",
      " [51 0 2 0 13.597000000000001]\n",
      " [69 1 1 0 15.478]\n",
      " [37 0 0 1 23.090999999999998]\n",
      " [50 0 2 1 17.211]\n",
      " [41 1 0 1 15.155999999999999]\n",
      " [29 0 0 0 29.45]\n",
      " [42 0 1 1 29.271]\n",
      " [56 1 1 0 15.015]\n",
      " [36 1 1 1 11.424000000000001]\n",
      " [58 0 1 0 38.247]\n",
      " [56 0 0 0 25.395]\n",
      " [20 1 0 1 35.639]\n",
      " [31 1 0 1 11.870999999999999]\n",
      " [45 0 0 0 12.854000000000001]\n",
      " [28 0 1 0 13.127]\n",
      " [22 1 0 1 28.294]\n",
      " [37 1 1 1 8.968]\n",
      " [22 1 2 0 11.953]\n",
      " [42 1 1 0 20.012999999999998]\n",
      " [72 1 0 1 9.677]\n",
      " [23 1 2 0 16.85]\n",
      " [50 1 0 0 7.49]\n",
      " [47 0 2 1 6.683]\n",
      " [35 1 1 1 9.17]\n",
      " [65 0 1 1 13.769]\n",
      " [20 0 2 1 9.281]\n",
      " [51 1 0 0 18.295]\n",
      " [67 1 2 1 9.514]\n",
      " [40 0 2 0 10.103]\n",
      " [32 0 0 1 10.292]\n",
      " [61 0 0 0 25.475]\n",
      " [28 1 2 0 27.064]\n",
      " [15 1 0 1 17.206]\n",
      " [36 0 2 0 16.753]\n",
      " [53 0 0 1 12.495]\n",
      " [19 0 0 1 25.969]\n",
      " [66 1 0 0 16.347]\n",
      " [35 1 2 1 7.845]\n",
      " [47 1 1 1 33.542]\n",
      " [32 0 2 0 7.477]\n",
      " [70 0 2 0 20.489]\n",
      " [52 1 1 1 32.922]\n",
      " [24 1 2 0 25.785999999999998]\n",
      " [42 0 0 0 21.035999999999998]\n",
      " [74 1 1 1 11.939]\n",
      " [55 0 0 0 10.977]\n",
      " [35 0 0 0 12.894]\n",
      " [51 1 0 1 11.343]\n",
      " [69 0 2 0 10.065]\n",
      " [49 1 0 1 6.269]\n",
      " [64 0 1 1 25.741]\n",
      " [60 1 0 1 8.621]\n",
      " [74 1 0 1 15.436]\n",
      " [39 1 0 0 9.664]\n",
      " [61 1 2 0 9.443]\n",
      " [37 0 1 1 12.005999999999998]\n",
      " [26 0 0 1 12.307]\n",
      " [22 1 1 0 8.151]\n",
      " [49 1 0 1 8.7]\n",
      " [68 1 0 0 11.009]\n",
      " [55 1 2 1 7.261]\n",
      " [49 1 1 0 10.537]\n",
      " [31 1 0 1 11.227]\n",
      " [53 1 1 0 22.963]\n",
      " [59 0 1 0 10.444]\n",
      " [34 0 1 1 12.923]\n",
      " [30 0 2 0 10.443]\n",
      " [43 1 2 1 12.859000000000002]\n",
      " [21 0 0 1 28.631999999999998]\n",
      " [16 1 0 1 19.007]\n",
      " [38 1 1 0 18.295]\n",
      " [58 0 1 0 26.645]\n",
      " [57 0 2 0 14.216]\n",
      " [51 0 1 1 23.003]\n",
      " [20 0 0 0 11.262]\n",
      " [28 0 2 0 12.879000000000001]\n",
      " [45 1 1 1 10.017000000000001]\n",
      " [39 0 2 1 17.225]\n",
      " [42 1 0 1 12.765999999999998]\n",
      " [73 0 0 0 18.348]\n",
      " [48 1 0 1 10.446]\n",
      " [25 1 2 0 19.011]\n",
      " [39 1 2 0 15.969000000000001]\n",
      " [67 0 2 0 15.890999999999998]\n",
      " [22 0 0 1 22.818]\n",
      " [59 0 2 0 13.884]\n",
      " [20 0 1 1 11.686]\n",
      " [36 0 0 1 15.49]\n",
      " [18 0 0 0 37.188]\n",
      " [57 0 2 1 25.893]\n",
      " [65 1 0 1 34.997]\n",
      " [64 1 0 1 20.932]\n",
      " [58 1 0 0 18.991]\n",
      " [72 1 1 0 16.31]\n",
      " [72 1 1 0 6.769]\n",
      " [46 0 0 0 34.686]\n",
      " [16 1 1 0 12.005999999999998]\n",
      " [23 1 2 1 14.02]\n",
      " [40 0 1 1 11.349]], test: [[74 0 1 0 20.941999999999997]\n",
      " [32 1 0 1 9.445]\n",
      " [66 0 2 1 8.107000000000001]\n",
      " [64 1 2 0 7.761]\n",
      " [32 0 1 0 9.712]\n",
      " [62 1 2 0 16.594]\n",
      " [15 0 0 1 16.725]\n",
      " [56 1 2 0 8.966000000000001]\n",
      " [34 1 2 0 22.456]\n",
      " [49 1 1 1 13.597999999999999]\n",
      " [61 0 1 1 7.34]\n",
      " [72 0 1 1 14.642000000000001]\n",
      " [37 1 1 1 16.724]\n",
      " [57 0 0 1 9.945]\n",
      " [41 0 1 1 18.739]\n",
      " [70 1 0 0 9.849]\n",
      " [47 1 0 0 10.402999999999999]\n",
      " [23 1 0 0 8.011000000000001]\n",
      " [56 0 1 0 11.567]\n",
      " [52 1 2 0 9.894]]\n",
      "train: [[47 1 1 0 13.093]\n",
      " [28 0 2 0 7.797999999999999]\n",
      " [61 0 1 0 18.043]\n",
      " [22 0 2 0 8.607000000000001]\n",
      " [41 1 1 0 11.037]\n",
      " [60 1 2 0 15.171]\n",
      " [43 1 1 1 19.368]\n",
      " [47 0 1 0 11.767000000000001]\n",
      " [34 0 0 1 19.199]\n",
      " [43 1 1 0 15.376]\n",
      " [74 0 1 0 20.941999999999997]\n",
      " [50 0 2 0 12.703]\n",
      " [16 0 0 1 15.515999999999998]\n",
      " [69 1 1 1 11.455]\n",
      " [43 1 0 0 13.972000000000001]\n",
      " [23 1 1 0 7.297999999999999]\n",
      " [32 0 0 1 25.974]\n",
      " [57 1 1 1 19.128]\n",
      " [47 1 1 1 30.568]\n",
      " [48 0 1 0 15.036]\n",
      " [33 0 1 0 33.486]\n",
      " [28 0 0 1 18.809]\n",
      " [31 1 0 0 30.366]\n",
      " [49 0 2 1 9.381]\n",
      " [39 0 1 1 22.697]\n",
      " [45 1 1 0 17.951]\n",
      " [18 0 2 1 8.75]\n",
      " [74 1 0 0 9.567]\n",
      " [49 1 1 1 11.014000000000001]\n",
      " [65 0 0 1 31.875999999999998]\n",
      " [53 1 2 0 14.133]\n",
      " [46 1 2 1 7.285]\n",
      " [32 1 0 1 9.445]\n",
      " [39 1 1 1 13.937999999999999]\n",
      " [39 0 2 1 9.709]\n",
      " [15 1 2 0 9.084]\n",
      " [73 0 2 0 19.221]\n",
      " [58 0 0 1 14.239]\n",
      " [50 1 2 1 15.79]\n",
      " [23 1 2 0 12.26]\n",
      " [50 0 2 1 12.295]\n",
      " [66 0 2 1 8.107000000000001]\n",
      " [68 1 1 0 10.290999999999999]\n",
      " [23 1 2 0 31.686]\n",
      " [28 0 1 0 19.796]\n",
      " [58 0 0 0 19.416]\n",
      " [67 1 2 1 10.898]\n",
      " [62 1 1 1 27.183000000000003]\n",
      " [24 0 0 1 18.457]\n",
      " [68 0 0 1 10.189]\n",
      " [65 1 0 1 11.34]\n",
      " [40 1 0 0 27.826]\n",
      " [60 1 2 1 10.091000000000001]\n",
      " [34 1 0 0 18.703]\n",
      " [38 0 1 1 29.875]\n",
      " [24 1 0 1 9.475]\n",
      " [45 1 1 1 8.37]\n",
      " [60 0 0 0 13.302999999999999]\n",
      " [29 1 0 0 12.856]\n",
      " [17 1 2 1 10.832]\n",
      " [54 1 2 0 24.658]\n",
      " [18 0 0 1 24.276]\n",
      " [28 0 2 0 19.675]\n",
      " [24 0 2 0 10.605]\n",
      " [41 0 2 1 22.905]\n",
      " [31 1 0 1 17.069000000000003]\n",
      " [36 0 0 0 11.198]\n",
      " [19 0 0 0 13.312999999999999]\n",
      " [32 0 1 1 10.84]\n",
      " [60 1 0 0 13.934000000000001]\n",
      " [64 1 2 0 7.761]\n",
      " [32 0 1 0 9.712]\n",
      " [38 0 0 1 11.325999999999999]\n",
      " [47 0 1 0 10.067]\n",
      " [51 0 2 0 13.597000000000001]\n",
      " [69 1 1 0 15.478]\n",
      " [50 0 2 1 17.211]\n",
      " [62 1 2 0 16.594]\n",
      " [29 0 0 0 29.45]\n",
      " [42 0 1 1 29.271]\n",
      " [56 1 1 0 15.015]\n",
      " [36 1 1 1 11.424000000000001]\n",
      " [58 0 1 0 38.247]\n",
      " [56 0 0 0 25.395]\n",
      " [20 1 0 1 35.639]\n",
      " [15 0 0 1 16.725]\n",
      " [31 1 0 1 11.870999999999999]\n",
      " [45 0 0 0 12.854000000000001]\n",
      " [28 0 1 0 13.127]\n",
      " [56 1 2 0 8.966000000000001]\n",
      " [22 1 0 1 28.294]\n",
      " [37 1 1 1 8.968]\n",
      " [22 1 2 0 11.953]\n",
      " [42 1 1 0 20.012999999999998]\n",
      " [72 1 0 1 9.677]\n",
      " [23 1 2 0 16.85]\n",
      " [50 1 0 0 7.49]\n",
      " [47 0 2 1 6.683]\n",
      " [65 0 1 1 13.769]\n",
      " [20 0 2 1 9.281]\n",
      " [51 1 0 0 18.295]\n",
      " [67 1 2 1 9.514]\n",
      " [40 0 2 0 10.103]\n",
      " [32 0 0 1 10.292]\n",
      " [61 0 0 0 25.475]\n",
      " [28 1 2 0 27.064]\n",
      " [15 1 0 1 17.206]\n",
      " [34 1 2 0 22.456]\n",
      " [36 0 2 0 16.753]\n",
      " [53 0 0 1 12.495]\n",
      " [19 0 0 1 25.969]\n",
      " [66 1 0 0 16.347]\n",
      " [35 1 2 1 7.845]\n",
      " [47 1 1 1 33.542]\n",
      " [32 0 2 0 7.477]\n",
      " [52 1 1 1 32.922]\n",
      " [49 1 1 1 13.597999999999999]\n",
      " [24 1 2 0 25.785999999999998]\n",
      " [42 0 0 0 21.035999999999998]\n",
      " [74 1 1 1 11.939]\n",
      " [55 0 0 0 10.977]\n",
      " [35 0 0 0 12.894]\n",
      " [51 1 0 1 11.343]\n",
      " [69 0 2 0 10.065]\n",
      " [49 1 0 1 6.269]\n",
      " [64 0 1 1 25.741]\n",
      " [60 1 0 1 8.621]\n",
      " [74 1 0 1 15.436]\n",
      " [39 1 0 0 9.664]\n",
      " [61 1 2 0 9.443]\n",
      " [37 0 1 1 12.005999999999998]\n",
      " [26 0 0 1 12.307]\n",
      " [61 0 1 1 7.34]\n",
      " [22 1 1 0 8.151]\n",
      " [68 1 0 0 11.009]\n",
      " [72 0 1 1 14.642000000000001]\n",
      " [37 1 1 1 16.724]\n",
      " [31 1 0 1 11.227]\n",
      " [53 1 1 0 22.963]\n",
      " [59 0 1 0 10.444]\n",
      " [34 0 1 1 12.923]\n",
      " [30 0 2 0 10.443]\n",
      " [57 0 0 1 9.945]\n",
      " [43 1 2 1 12.859000000000002]\n",
      " [21 0 0 1 28.631999999999998]\n",
      " [16 1 0 1 19.007]\n",
      " [38 1 1 0 18.295]\n",
      " [58 0 1 0 26.645]\n",
      " [51 0 1 1 23.003]\n",
      " [20 0 0 0 11.262]\n",
      " [28 0 2 0 12.879000000000001]\n",
      " [45 1 1 1 10.017000000000001]\n",
      " [39 0 2 1 17.225]\n",
      " [41 0 1 1 18.739]\n",
      " [42 1 0 1 12.765999999999998]\n",
      " [73 0 0 0 18.348]\n",
      " [48 1 0 1 10.446]\n",
      " [25 1 2 0 19.011]\n",
      " [39 1 2 0 15.969000000000001]\n",
      " [67 0 2 0 15.890999999999998]\n",
      " [22 0 0 1 22.818]\n",
      " [59 0 2 0 13.884]\n",
      " [20 0 1 1 11.686]\n",
      " [36 0 0 1 15.49]\n",
      " [18 0 0 0 37.188]\n",
      " [57 0 2 1 25.893]\n",
      " [70 1 0 0 9.849]\n",
      " [47 1 0 0 10.402999999999999]\n",
      " [65 1 0 1 34.997]\n",
      " [64 1 0 1 20.932]\n",
      " [58 1 0 0 18.991]\n",
      " [23 1 0 0 8.011000000000001]\n",
      " [72 1 1 0 16.31]\n",
      " [72 1 1 0 6.769]\n",
      " [46 0 0 0 34.686]\n",
      " [56 0 1 0 11.567]\n",
      " [16 1 1 0 12.005999999999998]\n",
      " [52 1 2 0 9.894]\n",
      " [23 1 2 1 14.02]\n",
      " [40 0 1 1 11.349]], test: [[23 0 0 0 25.355]\n",
      " [47 1 1 0 10.113999999999999]\n",
      " [49 0 2 0 16.275]\n",
      " [63 1 2 0 25.916999999999998]\n",
      " [37 0 0 0 13.091]\n",
      " [26 0 1 0 14.16]\n",
      " [67 1 1 1 20.693]\n",
      " [68 0 2 1 27.05]\n",
      " [70 1 0 0 13.967]\n",
      " [26 1 1 1 20.909000000000002]\n",
      " [26 0 0 1 19.160999999999998]\n",
      " [59 1 0 0 13.935]\n",
      " [37 0 0 1 23.090999999999998]\n",
      " [41 1 0 1 15.155999999999999]\n",
      " [35 1 1 1 9.17]\n",
      " [70 0 2 0 20.489]\n",
      " [49 1 0 1 8.7]\n",
      " [55 1 2 1 7.261]\n",
      " [49 1 1 0 10.537]\n",
      " [57 0 2 0 14.216]]\n",
      "train: [[23 0 0 0 25.355]\n",
      " [47 1 1 0 13.093]\n",
      " [47 1 1 0 10.113999999999999]\n",
      " [28 0 2 0 7.797999999999999]\n",
      " [61 0 1 0 18.043]\n",
      " [22 0 2 0 8.607000000000001]\n",
      " [49 0 2 0 16.275]\n",
      " [41 1 1 0 11.037]\n",
      " [60 1 2 0 15.171]\n",
      " [34 0 0 1 19.199]\n",
      " [43 1 1 0 15.376]\n",
      " [74 0 1 0 20.941999999999997]\n",
      " [50 0 2 0 12.703]\n",
      " [16 0 0 1 15.515999999999998]\n",
      " [69 1 1 1 11.455]\n",
      " [43 1 0 0 13.972000000000001]\n",
      " [23 1 1 0 7.297999999999999]\n",
      " [32 0 0 1 25.974]\n",
      " [57 1 1 1 19.128]\n",
      " [63 1 2 0 25.916999999999998]\n",
      " [47 1 1 1 30.568]\n",
      " [33 0 1 0 33.486]\n",
      " [28 0 0 1 18.809]\n",
      " [31 1 0 0 30.366]\n",
      " [49 0 2 1 9.381]\n",
      " [39 0 1 1 22.697]\n",
      " [45 1 1 0 17.951]\n",
      " [18 0 2 1 8.75]\n",
      " [74 1 0 0 9.567]\n",
      " [65 0 0 1 31.875999999999998]\n",
      " [53 1 2 0 14.133]\n",
      " [46 1 2 1 7.285]\n",
      " [32 1 0 1 9.445]\n",
      " [39 1 1 1 13.937999999999999]\n",
      " [39 0 2 1 9.709]\n",
      " [15 1 2 0 9.084]\n",
      " [73 0 2 0 19.221]\n",
      " [58 0 0 1 14.239]\n",
      " [50 1 2 1 15.79]\n",
      " [23 1 2 0 12.26]\n",
      " [50 0 2 1 12.295]\n",
      " [66 0 2 1 8.107000000000001]\n",
      " [37 0 0 0 13.091]\n",
      " [68 1 1 0 10.290999999999999]\n",
      " [23 1 2 0 31.686]\n",
      " [28 0 1 0 19.796]\n",
      " [58 0 0 0 19.416]\n",
      " [67 1 2 1 10.898]\n",
      " [62 1 1 1 27.183000000000003]\n",
      " [24 0 0 1 18.457]\n",
      " [68 0 0 1 10.189]\n",
      " [26 0 1 0 14.16]\n",
      " [65 1 0 1 11.34]\n",
      " [40 1 0 0 27.826]\n",
      " [60 1 2 1 10.091000000000001]\n",
      " [34 1 0 0 18.703]\n",
      " [38 0 1 1 29.875]\n",
      " [24 1 0 1 9.475]\n",
      " [67 1 1 1 20.693]\n",
      " [45 1 1 1 8.37]\n",
      " [60 0 0 0 13.302999999999999]\n",
      " [68 0 2 1 27.05]\n",
      " [29 1 0 0 12.856]\n",
      " [17 1 2 1 10.832]\n",
      " [54 1 2 0 24.658]\n",
      " [18 0 0 1 24.276]\n",
      " [70 1 0 0 13.967]\n",
      " [28 0 2 0 19.675]\n",
      " [24 0 2 0 10.605]\n",
      " [41 0 2 1 22.905]\n",
      " [26 1 1 1 20.909000000000002]\n",
      " [36 0 0 0 11.198]\n",
      " [26 0 0 1 19.160999999999998]\n",
      " [19 0 0 0 13.312999999999999]\n",
      " [32 0 1 1 10.84]\n",
      " [60 1 0 0 13.934000000000001]\n",
      " [64 1 2 0 7.761]\n",
      " [32 0 1 0 9.712]\n",
      " [47 0 1 0 10.067]\n",
      " [59 1 0 0 13.935]\n",
      " [51 0 2 0 13.597000000000001]\n",
      " [37 0 0 1 23.090999999999998]\n",
      " [50 0 2 1 17.211]\n",
      " [62 1 2 0 16.594]\n",
      " [41 1 0 1 15.155999999999999]\n",
      " [42 0 1 1 29.271]\n",
      " [56 1 1 0 15.015]\n",
      " [36 1 1 1 11.424000000000001]\n",
      " [58 0 1 0 38.247]\n",
      " [56 0 0 0 25.395]\n",
      " [20 1 0 1 35.639]\n",
      " [15 0 0 1 16.725]\n",
      " [45 0 0 0 12.854000000000001]\n",
      " [28 0 1 0 13.127]\n",
      " [56 1 2 0 8.966000000000001]\n",
      " [37 1 1 1 8.968]\n",
      " [22 1 2 0 11.953]\n",
      " [42 1 1 0 20.012999999999998]\n",
      " [72 1 0 1 9.677]\n",
      " [23 1 2 0 16.85]\n",
      " [50 1 0 0 7.49]\n",
      " [47 0 2 1 6.683]\n",
      " [35 1 1 1 9.17]\n",
      " [65 0 1 1 13.769]\n",
      " [20 0 2 1 9.281]\n",
      " [51 1 0 0 18.295]\n",
      " [67 1 2 1 9.514]\n",
      " [40 0 2 0 10.103]\n",
      " [32 0 0 1 10.292]\n",
      " [61 0 0 0 25.475]\n",
      " [28 1 2 0 27.064]\n",
      " [15 1 0 1 17.206]\n",
      " [34 1 2 0 22.456]\n",
      " [36 0 2 0 16.753]\n",
      " [53 0 0 1 12.495]\n",
      " [35 1 2 1 7.845]\n",
      " [47 1 1 1 33.542]\n",
      " [32 0 2 0 7.477]\n",
      " [70 0 2 0 20.489]\n",
      " [52 1 1 1 32.922]\n",
      " [49 1 1 1 13.597999999999999]\n",
      " [24 1 2 0 25.785999999999998]\n",
      " [42 0 0 0 21.035999999999998]\n",
      " [74 1 1 1 11.939]\n",
      " [55 0 0 0 10.977]\n",
      " [35 0 0 0 12.894]\n",
      " [51 1 0 1 11.343]\n",
      " [69 0 2 0 10.065]\n",
      " [49 1 0 1 6.269]\n",
      " [64 0 1 1 25.741]\n",
      " [60 1 0 1 8.621]\n",
      " [39 1 0 0 9.664]\n",
      " [37 0 1 1 12.005999999999998]\n",
      " [61 0 1 1 7.34]\n",
      " [22 1 1 0 8.151]\n",
      " [49 1 0 1 8.7]\n",
      " [68 1 0 0 11.009]\n",
      " [55 1 2 1 7.261]\n",
      " [72 0 1 1 14.642000000000001]\n",
      " [37 1 1 1 16.724]\n",
      " [49 1 1 0 10.537]\n",
      " [31 1 0 1 11.227]\n",
      " [53 1 1 0 22.963]\n",
      " [59 0 1 0 10.444]\n",
      " [34 0 1 1 12.923]\n",
      " [57 0 0 1 9.945]\n",
      " [43 1 2 1 12.859000000000002]\n",
      " [21 0 0 1 28.631999999999998]\n",
      " [38 1 1 0 18.295]\n",
      " [58 0 1 0 26.645]\n",
      " [57 0 2 0 14.216]\n",
      " [51 0 1 1 23.003]\n",
      " [20 0 0 0 11.262]\n",
      " [45 1 1 1 10.017000000000001]\n",
      " [39 0 2 1 17.225]\n",
      " [41 0 1 1 18.739]\n",
      " [42 1 0 1 12.765999999999998]\n",
      " [73 0 0 0 18.348]\n",
      " [48 1 0 1 10.446]\n",
      " [25 1 2 0 19.011]\n",
      " [39 1 2 0 15.969000000000001]\n",
      " [67 0 2 0 15.890999999999998]\n",
      " [59 0 2 0 13.884]\n",
      " [36 0 0 1 15.49]\n",
      " [18 0 0 0 37.188]\n",
      " [57 0 2 1 25.893]\n",
      " [70 1 0 0 9.849]\n",
      " [47 1 0 0 10.402999999999999]\n",
      " [65 1 0 1 34.997]\n",
      " [64 1 0 1 20.932]\n",
      " [58 1 0 0 18.991]\n",
      " [23 1 0 0 8.011000000000001]\n",
      " [72 1 1 0 16.31]\n",
      " [72 1 1 0 6.769]\n",
      " [46 0 0 0 34.686]\n",
      " [56 0 1 0 11.567]\n",
      " [16 1 1 0 12.005999999999998]\n",
      " [52 1 2 0 9.894]\n",
      " [23 1 2 1 14.02]\n",
      " [40 0 1 1 11.349]], test: [[43 1 1 1 19.368]\n",
      " [47 0 1 0 11.767000000000001]\n",
      " [48 0 1 0 15.036]\n",
      " [49 1 1 1 11.014000000000001]\n",
      " [31 1 0 1 17.069000000000003]\n",
      " [38 0 0 1 11.325999999999999]\n",
      " [69 1 1 0 15.478]\n",
      " [29 0 0 0 29.45]\n",
      " [31 1 0 1 11.870999999999999]\n",
      " [22 1 0 1 28.294]\n",
      " [19 0 0 1 25.969]\n",
      " [66 1 0 0 16.347]\n",
      " [74 1 0 1 15.436]\n",
      " [61 1 2 0 9.443]\n",
      " [26 0 0 1 12.307]\n",
      " [30 0 2 0 10.443]\n",
      " [16 1 0 1 19.007]\n",
      " [28 0 2 0 12.879000000000001]\n",
      " [22 0 0 1 22.818]\n",
      " [20 0 1 1 11.686]]\n",
      "train: [[23 0 0 0 25.355]\n",
      " [47 1 1 0 13.093]\n",
      " [47 1 1 0 10.113999999999999]\n",
      " [61 0 1 0 18.043]\n",
      " [22 0 2 0 8.607000000000001]\n",
      " [49 0 2 0 16.275]\n",
      " [41 1 1 0 11.037]\n",
      " [60 1 2 0 15.171]\n",
      " [43 1 1 1 19.368]\n",
      " [47 0 1 0 11.767000000000001]\n",
      " [34 0 0 1 19.199]\n",
      " [43 1 1 0 15.376]\n",
      " [74 0 1 0 20.941999999999997]\n",
      " [50 0 2 0 12.703]\n",
      " [69 1 1 1 11.455]\n",
      " [43 1 0 0 13.972000000000001]\n",
      " [23 1 1 0 7.297999999999999]\n",
      " [32 0 0 1 25.974]\n",
      " [57 1 1 1 19.128]\n",
      " [63 1 2 0 25.916999999999998]\n",
      " [47 1 1 1 30.568]\n",
      " [48 0 1 0 15.036]\n",
      " [28 0 0 1 18.809]\n",
      " [49 0 2 1 9.381]\n",
      " [39 0 1 1 22.697]\n",
      " [45 1 1 0 17.951]\n",
      " [18 0 2 1 8.75]\n",
      " [74 1 0 0 9.567]\n",
      " [49 1 1 1 11.014000000000001]\n",
      " [65 0 0 1 31.875999999999998]\n",
      " [53 1 2 0 14.133]\n",
      " [46 1 2 1 7.285]\n",
      " [32 1 0 1 9.445]\n",
      " [39 1 1 1 13.937999999999999]\n",
      " [39 0 2 1 9.709]\n",
      " [15 1 2 0 9.084]\n",
      " [73 0 2 0 19.221]\n",
      " [50 1 2 1 15.79]\n",
      " [50 0 2 1 12.295]\n",
      " [66 0 2 1 8.107000000000001]\n",
      " [37 0 0 0 13.091]\n",
      " [68 1 1 0 10.290999999999999]\n",
      " [23 1 2 0 31.686]\n",
      " [58 0 0 0 19.416]\n",
      " [67 1 2 1 10.898]\n",
      " [24 0 0 1 18.457]\n",
      " [68 0 0 1 10.189]\n",
      " [26 0 1 0 14.16]\n",
      " [65 1 0 1 11.34]\n",
      " [40 1 0 0 27.826]\n",
      " [60 1 2 1 10.091000000000001]\n",
      " [34 1 0 0 18.703]\n",
      " [38 0 1 1 29.875]\n",
      " [24 1 0 1 9.475]\n",
      " [67 1 1 1 20.693]\n",
      " [45 1 1 1 8.37]\n",
      " [68 0 2 1 27.05]\n",
      " [29 1 0 0 12.856]\n",
      " [17 1 2 1 10.832]\n",
      " [54 1 2 0 24.658]\n",
      " [18 0 0 1 24.276]\n",
      " [70 1 0 0 13.967]\n",
      " [28 0 2 0 19.675]\n",
      " [24 0 2 0 10.605]\n",
      " [41 0 2 1 22.905]\n",
      " [31 1 0 1 17.069000000000003]\n",
      " [26 1 1 1 20.909000000000002]\n",
      " [26 0 0 1 19.160999999999998]\n",
      " [19 0 0 0 13.312999999999999]\n",
      " [32 0 1 1 10.84]\n",
      " [64 1 2 0 7.761]\n",
      " [32 0 1 0 9.712]\n",
      " [38 0 0 1 11.325999999999999]\n",
      " [47 0 1 0 10.067]\n",
      " [59 1 0 0 13.935]\n",
      " [51 0 2 0 13.597000000000001]\n",
      " [69 1 1 0 15.478]\n",
      " [37 0 0 1 23.090999999999998]\n",
      " [50 0 2 1 17.211]\n",
      " [62 1 2 0 16.594]\n",
      " [41 1 0 1 15.155999999999999]\n",
      " [29 0 0 0 29.45]\n",
      " [42 0 1 1 29.271]\n",
      " [56 1 1 0 15.015]\n",
      " [36 1 1 1 11.424000000000001]\n",
      " [58 0 1 0 38.247]\n",
      " [56 0 0 0 25.395]\n",
      " [20 1 0 1 35.639]\n",
      " [15 0 0 1 16.725]\n",
      " [31 1 0 1 11.870999999999999]\n",
      " [45 0 0 0 12.854000000000001]\n",
      " [28 0 1 0 13.127]\n",
      " [56 1 2 0 8.966000000000001]\n",
      " [22 1 0 1 28.294]\n",
      " [37 1 1 1 8.968]\n",
      " [22 1 2 0 11.953]\n",
      " [42 1 1 0 20.012999999999998]\n",
      " [72 1 0 1 9.677]\n",
      " [50 1 0 0 7.49]\n",
      " [35 1 1 1 9.17]\n",
      " [65 0 1 1 13.769]\n",
      " [20 0 2 1 9.281]\n",
      " [51 1 0 0 18.295]\n",
      " [67 1 2 1 9.514]\n",
      " [40 0 2 0 10.103]\n",
      " [32 0 0 1 10.292]\n",
      " [61 0 0 0 25.475]\n",
      " [28 1 2 0 27.064]\n",
      " [15 1 0 1 17.206]\n",
      " [34 1 2 0 22.456]\n",
      " [36 0 2 0 16.753]\n",
      " [53 0 0 1 12.495]\n",
      " [19 0 0 1 25.969]\n",
      " [66 1 0 0 16.347]\n",
      " [35 1 2 1 7.845]\n",
      " [47 1 1 1 33.542]\n",
      " [32 0 2 0 7.477]\n",
      " [70 0 2 0 20.489]\n",
      " [49 1 1 1 13.597999999999999]\n",
      " [24 1 2 0 25.785999999999998]\n",
      " [42 0 0 0 21.035999999999998]\n",
      " [55 0 0 0 10.977]\n",
      " [35 0 0 0 12.894]\n",
      " [51 1 0 1 11.343]\n",
      " [69 0 2 0 10.065]\n",
      " [49 1 0 1 6.269]\n",
      " [64 0 1 1 25.741]\n",
      " [60 1 0 1 8.621]\n",
      " [74 1 0 1 15.436]\n",
      " [39 1 0 0 9.664]\n",
      " [61 1 2 0 9.443]\n",
      " [37 0 1 1 12.005999999999998]\n",
      " [26 0 0 1 12.307]\n",
      " [61 0 1 1 7.34]\n",
      " [49 1 0 1 8.7]\n",
      " [55 1 2 1 7.261]\n",
      " [72 0 1 1 14.642000000000001]\n",
      " [37 1 1 1 16.724]\n",
      " [49 1 1 0 10.537]\n",
      " [31 1 0 1 11.227]\n",
      " [53 1 1 0 22.963]\n",
      " [59 0 1 0 10.444]\n",
      " [34 0 1 1 12.923]\n",
      " [30 0 2 0 10.443]\n",
      " [57 0 0 1 9.945]\n",
      " [43 1 2 1 12.859000000000002]\n",
      " [16 1 0 1 19.007]\n",
      " [38 1 1 0 18.295]\n",
      " [58 0 1 0 26.645]\n",
      " [57 0 2 0 14.216]\n",
      " [51 0 1 1 23.003]\n",
      " [28 0 2 0 12.879000000000001]\n",
      " [45 1 1 1 10.017000000000001]\n",
      " [39 0 2 1 17.225]\n",
      " [41 0 1 1 18.739]\n",
      " [42 1 0 1 12.765999999999998]\n",
      " [73 0 0 0 18.348]\n",
      " [48 1 0 1 10.446]\n",
      " [25 1 2 0 19.011]\n",
      " [39 1 2 0 15.969000000000001]\n",
      " [67 0 2 0 15.890999999999998]\n",
      " [22 0 0 1 22.818]\n",
      " [59 0 2 0 13.884]\n",
      " [20 0 1 1 11.686]\n",
      " [36 0 0 1 15.49]\n",
      " [18 0 0 0 37.188]\n",
      " [57 0 2 1 25.893]\n",
      " [70 1 0 0 9.849]\n",
      " [47 1 0 0 10.402999999999999]\n",
      " [64 1 0 1 20.932]\n",
      " [58 1 0 0 18.991]\n",
      " [23 1 0 0 8.011000000000001]\n",
      " [72 1 1 0 16.31]\n",
      " [72 1 1 0 6.769]\n",
      " [46 0 0 0 34.686]\n",
      " [56 0 1 0 11.567]\n",
      " [16 1 1 0 12.005999999999998]\n",
      " [52 1 2 0 9.894]\n",
      " [23 1 2 1 14.02]\n",
      " [40 0 1 1 11.349]], test: [[28 0 2 0 7.797999999999999]\n",
      " [16 0 0 1 15.515999999999998]\n",
      " [33 0 1 0 33.486]\n",
      " [31 1 0 0 30.366]\n",
      " [58 0 0 1 14.239]\n",
      " [23 1 2 0 12.26]\n",
      " [28 0 1 0 19.796]\n",
      " [62 1 1 1 27.183000000000003]\n",
      " [60 0 0 0 13.302999999999999]\n",
      " [36 0 0 0 11.198]\n",
      " [60 1 0 0 13.934000000000001]\n",
      " [23 1 2 0 16.85]\n",
      " [47 0 2 1 6.683]\n",
      " [52 1 1 1 32.922]\n",
      " [74 1 1 1 11.939]\n",
      " [22 1 1 0 8.151]\n",
      " [68 1 0 0 11.009]\n",
      " [21 0 0 1 28.631999999999998]\n",
      " [20 0 0 0 11.262]\n",
      " [65 1 0 1 34.997]]\n",
      "train: [[23 0 0 0 25.355]\n",
      " [47 1 1 0 10.113999999999999]\n",
      " [28 0 2 0 7.797999999999999]\n",
      " [61 0 1 0 18.043]\n",
      " [22 0 2 0 8.607000000000001]\n",
      " [49 0 2 0 16.275]\n",
      " [43 1 1 1 19.368]\n",
      " [47 0 1 0 11.767000000000001]\n",
      " [34 0 0 1 19.199]\n",
      " [43 1 1 0 15.376]\n",
      " [74 0 1 0 20.941999999999997]\n",
      " [50 0 2 0 12.703]\n",
      " [16 0 0 1 15.515999999999998]\n",
      " [69 1 1 1 11.455]\n",
      " [43 1 0 0 13.972000000000001]\n",
      " [23 1 1 0 7.297999999999999]\n",
      " [32 0 0 1 25.974]\n",
      " [57 1 1 1 19.128]\n",
      " [63 1 2 0 25.916999999999998]\n",
      " [48 0 1 0 15.036]\n",
      " [33 0 1 0 33.486]\n",
      " [28 0 0 1 18.809]\n",
      " [31 1 0 0 30.366]\n",
      " [49 0 2 1 9.381]\n",
      " [39 0 1 1 22.697]\n",
      " [45 1 1 0 17.951]\n",
      " [74 1 0 0 9.567]\n",
      " [49 1 1 1 11.014000000000001]\n",
      " [65 0 0 1 31.875999999999998]\n",
      " [53 1 2 0 14.133]\n",
      " [46 1 2 1 7.285]\n",
      " [32 1 0 1 9.445]\n",
      " [39 1 1 1 13.937999999999999]\n",
      " [39 0 2 1 9.709]\n",
      " [15 1 2 0 9.084]\n",
      " [73 0 2 0 19.221]\n",
      " [58 0 0 1 14.239]\n",
      " [50 1 2 1 15.79]\n",
      " [23 1 2 0 12.26]\n",
      " [50 0 2 1 12.295]\n",
      " [66 0 2 1 8.107000000000001]\n",
      " [37 0 0 0 13.091]\n",
      " [68 1 1 0 10.290999999999999]\n",
      " [23 1 2 0 31.686]\n",
      " [28 0 1 0 19.796]\n",
      " [67 1 2 1 10.898]\n",
      " [62 1 1 1 27.183000000000003]\n",
      " [24 0 0 1 18.457]\n",
      " [68 0 0 1 10.189]\n",
      " [26 0 1 0 14.16]\n",
      " [65 1 0 1 11.34]\n",
      " [60 1 2 1 10.091000000000001]\n",
      " [34 1 0 0 18.703]\n",
      " [67 1 1 1 20.693]\n",
      " [60 0 0 0 13.302999999999999]\n",
      " [68 0 2 1 27.05]\n",
      " [29 1 0 0 12.856]\n",
      " [17 1 2 1 10.832]\n",
      " [18 0 0 1 24.276]\n",
      " [70 1 0 0 13.967]\n",
      " [28 0 2 0 19.675]\n",
      " [24 0 2 0 10.605]\n",
      " [41 0 2 1 22.905]\n",
      " [31 1 0 1 17.069000000000003]\n",
      " [26 1 1 1 20.909000000000002]\n",
      " [36 0 0 0 11.198]\n",
      " [26 0 0 1 19.160999999999998]\n",
      " [19 0 0 0 13.312999999999999]\n",
      " [32 0 1 1 10.84]\n",
      " [60 1 0 0 13.934000000000001]\n",
      " [64 1 2 0 7.761]\n",
      " [32 0 1 0 9.712]\n",
      " [38 0 0 1 11.325999999999999]\n",
      " [47 0 1 0 10.067]\n",
      " [59 1 0 0 13.935]\n",
      " [69 1 1 0 15.478]\n",
      " [37 0 0 1 23.090999999999998]\n",
      " [50 0 2 1 17.211]\n",
      " [62 1 2 0 16.594]\n",
      " [41 1 0 1 15.155999999999999]\n",
      " [29 0 0 0 29.45]\n",
      " [42 0 1 1 29.271]\n",
      " [56 1 1 0 15.015]\n",
      " [36 1 1 1 11.424000000000001]\n",
      " [56 0 0 0 25.395]\n",
      " [20 1 0 1 35.639]\n",
      " [15 0 0 1 16.725]\n",
      " [31 1 0 1 11.870999999999999]\n",
      " [45 0 0 0 12.854000000000001]\n",
      " [28 0 1 0 13.127]\n",
      " [56 1 2 0 8.966000000000001]\n",
      " [22 1 0 1 28.294]\n",
      " [37 1 1 1 8.968]\n",
      " [22 1 2 0 11.953]\n",
      " [42 1 1 0 20.012999999999998]\n",
      " [72 1 0 1 9.677]\n",
      " [23 1 2 0 16.85]\n",
      " [50 1 0 0 7.49]\n",
      " [47 0 2 1 6.683]\n",
      " [35 1 1 1 9.17]\n",
      " [65 0 1 1 13.769]\n",
      " [20 0 2 1 9.281]\n",
      " [67 1 2 1 9.514]\n",
      " [40 0 2 0 10.103]\n",
      " [32 0 0 1 10.292]\n",
      " [61 0 0 0 25.475]\n",
      " [28 1 2 0 27.064]\n",
      " [34 1 2 0 22.456]\n",
      " [36 0 2 0 16.753]\n",
      " [53 0 0 1 12.495]\n",
      " [19 0 0 1 25.969]\n",
      " [66 1 0 0 16.347]\n",
      " [35 1 2 1 7.845]\n",
      " [32 0 2 0 7.477]\n",
      " [70 0 2 0 20.489]\n",
      " [52 1 1 1 32.922]\n",
      " [49 1 1 1 13.597999999999999]\n",
      " [24 1 2 0 25.785999999999998]\n",
      " [42 0 0 0 21.035999999999998]\n",
      " [74 1 1 1 11.939]\n",
      " [55 0 0 0 10.977]\n",
      " [35 0 0 0 12.894]\n",
      " [51 1 0 1 11.343]\n",
      " [69 0 2 0 10.065]\n",
      " [49 1 0 1 6.269]\n",
      " [60 1 0 1 8.621]\n",
      " [74 1 0 1 15.436]\n",
      " [39 1 0 0 9.664]\n",
      " [61 1 2 0 9.443]\n",
      " [37 0 1 1 12.005999999999998]\n",
      " [26 0 0 1 12.307]\n",
      " [61 0 1 1 7.34]\n",
      " [22 1 1 0 8.151]\n",
      " [49 1 0 1 8.7]\n",
      " [68 1 0 0 11.009]\n",
      " [55 1 2 1 7.261]\n",
      " [72 0 1 1 14.642000000000001]\n",
      " [37 1 1 1 16.724]\n",
      " [49 1 1 0 10.537]\n",
      " [31 1 0 1 11.227]\n",
      " [53 1 1 0 22.963]\n",
      " [59 0 1 0 10.444]\n",
      " [34 0 1 1 12.923]\n",
      " [30 0 2 0 10.443]\n",
      " [57 0 0 1 9.945]\n",
      " [43 1 2 1 12.859000000000002]\n",
      " [21 0 0 1 28.631999999999998]\n",
      " [16 1 0 1 19.007]\n",
      " [38 1 1 0 18.295]\n",
      " [58 0 1 0 26.645]\n",
      " [57 0 2 0 14.216]\n",
      " [51 0 1 1 23.003]\n",
      " [20 0 0 0 11.262]\n",
      " [28 0 2 0 12.879000000000001]\n",
      " [45 1 1 1 10.017000000000001]\n",
      " [39 0 2 1 17.225]\n",
      " [41 0 1 1 18.739]\n",
      " [42 1 0 1 12.765999999999998]\n",
      " [48 1 0 1 10.446]\n",
      " [25 1 2 0 19.011]\n",
      " [39 1 2 0 15.969000000000001]\n",
      " [67 0 2 0 15.890999999999998]\n",
      " [22 0 0 1 22.818]\n",
      " [59 0 2 0 13.884]\n",
      " [20 0 1 1 11.686]\n",
      " [36 0 0 1 15.49]\n",
      " [18 0 0 0 37.188]\n",
      " [57 0 2 1 25.893]\n",
      " [70 1 0 0 9.849]\n",
      " [47 1 0 0 10.402999999999999]\n",
      " [65 1 0 1 34.997]\n",
      " [64 1 0 1 20.932]\n",
      " [23 1 0 0 8.011000000000001]\n",
      " [72 1 1 0 16.31]\n",
      " [72 1 1 0 6.769]\n",
      " [46 0 0 0 34.686]\n",
      " [56 0 1 0 11.567]\n",
      " [52 1 2 0 9.894]\n",
      " [23 1 2 1 14.02]\n",
      " [40 0 1 1 11.349]], test: [[47 1 1 0 13.093]\n",
      " [41 1 1 0 11.037]\n",
      " [60 1 2 0 15.171]\n",
      " [47 1 1 1 30.568]\n",
      " [18 0 2 1 8.75]\n",
      " [58 0 0 0 19.416]\n",
      " [40 1 0 0 27.826]\n",
      " [38 0 1 1 29.875]\n",
      " [24 1 0 1 9.475]\n",
      " [45 1 1 1 8.37]\n",
      " [54 1 2 0 24.658]\n",
      " [51 0 2 0 13.597000000000001]\n",
      " [58 0 1 0 38.247]\n",
      " [51 1 0 0 18.295]\n",
      " [15 1 0 1 17.206]\n",
      " [47 1 1 1 33.542]\n",
      " [64 0 1 1 25.741]\n",
      " [73 0 0 0 18.348]\n",
      " [58 1 0 0 18.991]\n",
      " [16 1 1 0 12.005999999999998]]\n",
      "train: [[23 0 0 0 25.355]\n",
      " [47 1 1 0 13.093]\n",
      " [47 1 1 0 10.113999999999999]\n",
      " [28 0 2 0 7.797999999999999]\n",
      " [61 0 1 0 18.043]\n",
      " [22 0 2 0 8.607000000000001]\n",
      " [49 0 2 0 16.275]\n",
      " [41 1 1 0 11.037]\n",
      " [60 1 2 0 15.171]\n",
      " [43 1 1 1 19.368]\n",
      " [47 0 1 0 11.767000000000001]\n",
      " [34 0 0 1 19.199]\n",
      " [43 1 1 0 15.376]\n",
      " [74 0 1 0 20.941999999999997]\n",
      " [50 0 2 0 12.703]\n",
      " [16 0 0 1 15.515999999999998]\n",
      " [69 1 1 1 11.455]\n",
      " [43 1 0 0 13.972000000000001]\n",
      " [23 1 1 0 7.297999999999999]\n",
      " [32 0 0 1 25.974]\n",
      " [63 1 2 0 25.916999999999998]\n",
      " [47 1 1 1 30.568]\n",
      " [48 0 1 0 15.036]\n",
      " [33 0 1 0 33.486]\n",
      " [31 1 0 0 30.366]\n",
      " [49 0 2 1 9.381]\n",
      " [39 0 1 1 22.697]\n",
      " [45 1 1 0 17.951]\n",
      " [18 0 2 1 8.75]\n",
      " [74 1 0 0 9.567]\n",
      " [49 1 1 1 11.014000000000001]\n",
      " [65 0 0 1 31.875999999999998]\n",
      " [53 1 2 0 14.133]\n",
      " [46 1 2 1 7.285]\n",
      " [32 1 0 1 9.445]\n",
      " [39 0 2 1 9.709]\n",
      " [15 1 2 0 9.084]\n",
      " [73 0 2 0 19.221]\n",
      " [58 0 0 1 14.239]\n",
      " [50 1 2 1 15.79]\n",
      " [23 1 2 0 12.26]\n",
      " [50 0 2 1 12.295]\n",
      " [66 0 2 1 8.107000000000001]\n",
      " [37 0 0 0 13.091]\n",
      " [68 1 1 0 10.290999999999999]\n",
      " [23 1 2 0 31.686]\n",
      " [28 0 1 0 19.796]\n",
      " [58 0 0 0 19.416]\n",
      " [67 1 2 1 10.898]\n",
      " [62 1 1 1 27.183000000000003]\n",
      " [24 0 0 1 18.457]\n",
      " [68 0 0 1 10.189]\n",
      " [26 0 1 0 14.16]\n",
      " [65 1 0 1 11.34]\n",
      " [40 1 0 0 27.826]\n",
      " [60 1 2 1 10.091000000000001]\n",
      " [34 1 0 0 18.703]\n",
      " [38 0 1 1 29.875]\n",
      " [24 1 0 1 9.475]\n",
      " [67 1 1 1 20.693]\n",
      " [45 1 1 1 8.37]\n",
      " [60 0 0 0 13.302999999999999]\n",
      " [68 0 2 1 27.05]\n",
      " [29 1 0 0 12.856]\n",
      " [17 1 2 1 10.832]\n",
      " [54 1 2 0 24.658]\n",
      " [18 0 0 1 24.276]\n",
      " [70 1 0 0 13.967]\n",
      " [41 0 2 1 22.905]\n",
      " [31 1 0 1 17.069000000000003]\n",
      " [26 1 1 1 20.909000000000002]\n",
      " [36 0 0 0 11.198]\n",
      " [26 0 0 1 19.160999999999998]\n",
      " [19 0 0 0 13.312999999999999]\n",
      " [60 1 0 0 13.934000000000001]\n",
      " [64 1 2 0 7.761]\n",
      " [32 0 1 0 9.712]\n",
      " [38 0 0 1 11.325999999999999]\n",
      " [47 0 1 0 10.067]\n",
      " [59 1 0 0 13.935]\n",
      " [51 0 2 0 13.597000000000001]\n",
      " [69 1 1 0 15.478]\n",
      " [37 0 0 1 23.090999999999998]\n",
      " [50 0 2 1 17.211]\n",
      " [62 1 2 0 16.594]\n",
      " [41 1 0 1 15.155999999999999]\n",
      " [29 0 0 0 29.45]\n",
      " [42 0 1 1 29.271]\n",
      " [56 1 1 0 15.015]\n",
      " [36 1 1 1 11.424000000000001]\n",
      " [58 0 1 0 38.247]\n",
      " [56 0 0 0 25.395]\n",
      " [20 1 0 1 35.639]\n",
      " [15 0 0 1 16.725]\n",
      " [31 1 0 1 11.870999999999999]\n",
      " [28 0 1 0 13.127]\n",
      " [56 1 2 0 8.966000000000001]\n",
      " [22 1 0 1 28.294]\n",
      " [37 1 1 1 8.968]\n",
      " [22 1 2 0 11.953]\n",
      " [42 1 1 0 20.012999999999998]\n",
      " [72 1 0 1 9.677]\n",
      " [23 1 2 0 16.85]\n",
      " [50 1 0 0 7.49]\n",
      " [47 0 2 1 6.683]\n",
      " [35 1 1 1 9.17]\n",
      " [65 0 1 1 13.769]\n",
      " [20 0 2 1 9.281]\n",
      " [51 1 0 0 18.295]\n",
      " [67 1 2 1 9.514]\n",
      " [40 0 2 0 10.103]\n",
      " [32 0 0 1 10.292]\n",
      " [61 0 0 0 25.475]\n",
      " [28 1 2 0 27.064]\n",
      " [15 1 0 1 17.206]\n",
      " [34 1 2 0 22.456]\n",
      " [36 0 2 0 16.753]\n",
      " [53 0 0 1 12.495]\n",
      " [19 0 0 1 25.969]\n",
      " [66 1 0 0 16.347]\n",
      " [35 1 2 1 7.845]\n",
      " [47 1 1 1 33.542]\n",
      " [70 0 2 0 20.489]\n",
      " [52 1 1 1 32.922]\n",
      " [49 1 1 1 13.597999999999999]\n",
      " [74 1 1 1 11.939]\n",
      " [55 0 0 0 10.977]\n",
      " [51 1 0 1 11.343]\n",
      " [64 0 1 1 25.741]\n",
      " [74 1 0 1 15.436]\n",
      " [61 1 2 0 9.443]\n",
      " [26 0 0 1 12.307]\n",
      " [61 0 1 1 7.34]\n",
      " [22 1 1 0 8.151]\n",
      " [49 1 0 1 8.7]\n",
      " [68 1 0 0 11.009]\n",
      " [55 1 2 1 7.261]\n",
      " [72 0 1 1 14.642000000000001]\n",
      " [37 1 1 1 16.724]\n",
      " [49 1 1 0 10.537]\n",
      " [59 0 1 0 10.444]\n",
      " [34 0 1 1 12.923]\n",
      " [30 0 2 0 10.443]\n",
      " [57 0 0 1 9.945]\n",
      " [43 1 2 1 12.859000000000002]\n",
      " [21 0 0 1 28.631999999999998]\n",
      " [16 1 0 1 19.007]\n",
      " [38 1 1 0 18.295]\n",
      " [58 0 1 0 26.645]\n",
      " [57 0 2 0 14.216]\n",
      " [51 0 1 1 23.003]\n",
      " [20 0 0 0 11.262]\n",
      " [28 0 2 0 12.879000000000001]\n",
      " [45 1 1 1 10.017000000000001]\n",
      " [39 0 2 1 17.225]\n",
      " [41 0 1 1 18.739]\n",
      " [42 1 0 1 12.765999999999998]\n",
      " [73 0 0 0 18.348]\n",
      " [48 1 0 1 10.446]\n",
      " [25 1 2 0 19.011]\n",
      " [67 0 2 0 15.890999999999998]\n",
      " [22 0 0 1 22.818]\n",
      " [59 0 2 0 13.884]\n",
      " [20 0 1 1 11.686]\n",
      " [36 0 0 1 15.49]\n",
      " [18 0 0 0 37.188]\n",
      " [57 0 2 1 25.893]\n",
      " [70 1 0 0 9.849]\n",
      " [47 1 0 0 10.402999999999999]\n",
      " [65 1 0 1 34.997]\n",
      " [64 1 0 1 20.932]\n",
      " [58 1 0 0 18.991]\n",
      " [23 1 0 0 8.011000000000001]\n",
      " [72 1 1 0 6.769]\n",
      " [46 0 0 0 34.686]\n",
      " [56 0 1 0 11.567]\n",
      " [16 1 1 0 12.005999999999998]\n",
      " [52 1 2 0 9.894]\n",
      " [23 1 2 1 14.02]\n",
      " [40 0 1 1 11.349]], test: [[57 1 1 1 19.128]\n",
      " [28 0 0 1 18.809]\n",
      " [39 1 1 1 13.937999999999999]\n",
      " [28 0 2 0 19.675]\n",
      " [24 0 2 0 10.605]\n",
      " [32 0 1 1 10.84]\n",
      " [45 0 0 0 12.854000000000001]\n",
      " [32 0 2 0 7.477]\n",
      " [24 1 2 0 25.785999999999998]\n",
      " [42 0 0 0 21.035999999999998]\n",
      " [35 0 0 0 12.894]\n",
      " [69 0 2 0 10.065]\n",
      " [49 1 0 1 6.269]\n",
      " [60 1 0 1 8.621]\n",
      " [39 1 0 0 9.664]\n",
      " [37 0 1 1 12.005999999999998]\n",
      " [31 1 0 1 11.227]\n",
      " [53 1 1 0 22.963]\n",
      " [39 1 2 0 15.969000000000001]\n",
      " [72 1 1 0 16.31]]\n",
      "train: ['drugY' 'drugC' 'drugC' 'drugX' 'drugX' 'drugY' 'drugC' 'drugY' 'drugY'\n",
      " 'drugC' 'drugY' 'drugY' 'drugX' 'drugY' 'drugX' 'drugA' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugX'\n",
      " 'drugB' 'drugX' 'drugY' 'drugA' 'drugX' 'drugX' 'drugX' 'drugB' 'drugY'\n",
      " 'drugX' 'drugX' 'drugX' 'drugA' 'drugC' 'drugY' 'drugY' 'drugY' 'drugX'\n",
      " 'drugY' 'drugY' 'drugB' 'drugC' 'drugB' 'drugY' 'drugY' 'drugA' 'drugY'\n",
      " 'drugX' 'drugB' 'drugY' 'drugA' 'drugX' 'drugY' 'drugY' 'drugB' 'drugY'\n",
      " 'drugX' 'drugY' 'drugY' 'drugY' 'drugA' 'drugY' 'drugA' 'drugX' 'drugB'\n",
      " 'drugX' 'drugC' 'drugA' 'drugC' 'drugB' 'drugX' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugA'\n",
      " 'drugA' 'drugX' 'drugY' 'drugX' 'drugX' 'drugY' 'drugB' 'drugY' 'drugX'\n",
      " 'drugX' 'drugX' 'drugX' 'drugY' 'drugX' 'drugX' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugB' 'drugY' 'drugY' 'drugX' 'drugY' 'drugX' 'drugY'\n",
      " 'drugY' 'drugX' 'drugY' 'drugY' 'drugX' 'drugA' 'drugB' 'drugX' 'drugA'\n",
      " 'drugY' 'drugB' 'drugY' 'drugA' 'drugX' 'drugX' 'drugA' 'drugX' 'drugC'\n",
      " 'drugA' 'drugB' 'drugX' 'drugX' 'drugY' 'drugC' 'drugA' 'drugY' 'drugC'\n",
      " 'drugX' 'drugB' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugA'\n",
      " 'drugX' 'drugY' 'drugY' 'drugA' 'drugY' 'drugA' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugX' 'drugX' 'drugY' 'drugY' 'drugB' 'drugA' 'drugY' 'drugY'\n",
      " 'drugY' 'drugA' 'drugY' 'drugC' 'drugY' 'drugC' 'drugC' 'drugX' 'drugX'], test: ['drugY' 'drugY' 'drugC' 'drugY' 'drugX' 'drugX' 'drugY' 'drugX' 'drugY'\n",
      " 'drugY' 'drugX' 'drugC' 'drugA' 'drugA' 'drugB' 'drugX' 'drugY' 'drugX'\n",
      " 'drugY' 'drugX']\n",
      "train: ['drugY' 'drugC' 'drugC' 'drugX' 'drugY' 'drugX' 'drugY' 'drugC' 'drugY'\n",
      " 'drugY' 'drugC' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugA' 'drugC'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugX' 'drugX' 'drugY' 'drugX' 'drugX' 'drugA' 'drugX' 'drugX' 'drugY'\n",
      " 'drugB' 'drugY' 'drugX' 'drugX' 'drugA' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugB' 'drugC' 'drugB' 'drugY' 'drugX' 'drugY' 'drugY' 'drugA'\n",
      " 'drugY' 'drugX' 'drugB' 'drugY' 'drugA' 'drugX' 'drugY' 'drugB' 'drugY'\n",
      " 'drugX' 'drugY' 'drugY' 'drugA' 'drugY' 'drugA' 'drugX' 'drugB' 'drugX'\n",
      " 'drugC' 'drugA' 'drugC' 'drugB' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugY' 'drugA' 'drugA'\n",
      " 'drugC' 'drugX' 'drugY' 'drugX' 'drugX' 'drugY' 'drugB' 'drugY' 'drugA'\n",
      " 'drugX' 'drugX' 'drugX' 'drugX' 'drugY' 'drugX' 'drugX' 'drugA' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugB' 'drugY' 'drugY' 'drugX' 'drugY'\n",
      " 'drugX' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugX' 'drugB' 'drugA'\n",
      " 'drugB' 'drugX' 'drugA' 'drugY' 'drugB' 'drugY' 'drugA' 'drugX' 'drugX'\n",
      " 'drugA' 'drugX' 'drugC' 'drugA' 'drugB' 'drugX' 'drugX' 'drugY' 'drugC'\n",
      " 'drugA' 'drugY' 'drugC' 'drugX' 'drugX' 'drugB' 'drugY' 'drugY' 'drugY'\n",
      " 'drugX' 'drugY' 'drugA' 'drugX' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugX' 'drugX' 'drugY' 'drugY' 'drugY' 'drugB' 'drugA' 'drugY'\n",
      " 'drugY' 'drugY' 'drugA' 'drugY' 'drugC' 'drugC' 'drugX' 'drugX' 'drugX'], test: ['drugX' 'drugX' 'drugY' 'drugB' 'drugX' 'drugX' 'drugC' 'drugX' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugA' 'drugA' 'drugY'\n",
      " 'drugC' 'drugY']\n",
      "train: ['drugY' 'drugC' 'drugC' 'drugX' 'drugY' 'drugX' 'drugY' 'drugC' 'drugY'\n",
      " 'drugY' 'drugC' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugA' 'drugC'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY'\n",
      " 'drugY' 'drugX' 'drugB' 'drugX' 'drugX' 'drugX' 'drugA' 'drugX' 'drugX'\n",
      " 'drugY' 'drugB' 'drugY' 'drugX' 'drugX' 'drugX' 'drugA' 'drugC' 'drugY'\n",
      " 'drugY' 'drugY' 'drugX' 'drugY' 'drugB' 'drugC' 'drugY' 'drugX' 'drugY'\n",
      " 'drugY' 'drugA' 'drugY' 'drugX' 'drugB' 'drugY' 'drugA' 'drugX' 'drugY'\n",
      " 'drugY' 'drugB' 'drugY' 'drugX' 'drugY' 'drugY' 'drugY' 'drugA' 'drugY'\n",
      " 'drugA' 'drugX' 'drugB' 'drugX' 'drugC' 'drugA' 'drugC' 'drugB' 'drugX'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX'\n",
      " 'drugY' 'drugY' 'drugY' 'drugA' 'drugA' 'drugC' 'drugX' 'drugY' 'drugX'\n",
      " 'drugY' 'drugA' 'drugX' 'drugX' 'drugX' 'drugY' 'drugX' 'drugX' 'drugA'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugX' 'drugY'\n",
      " 'drugY' 'drugX' 'drugY' 'drugY' 'drugX' 'drugB' 'drugA' 'drugX' 'drugA'\n",
      " 'drugY' 'drugB' 'drugY' 'drugA' 'drugX' 'drugX' 'drugA' 'drugX' 'drugC'\n",
      " 'drugA' 'drugB' 'drugX' 'drugX' 'drugY' 'drugC' 'drugA' 'drugY' 'drugC'\n",
      " 'drugX' 'drugX' 'drugB' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX'\n",
      " 'drugY' 'drugA' 'drugX' 'drugX' 'drugY' 'drugY' 'drugA' 'drugY' 'drugA'\n",
      " 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugB' 'drugA' 'drugY'\n",
      " 'drugY' 'drugA' 'drugY' 'drugC' 'drugY' 'drugC' 'drugC' 'drugX' 'drugX'], test: ['drugX' 'drugY' 'drugY' 'drugX' 'drugY' 'drugB' 'drugY' 'drugX' 'drugY'\n",
      " 'drugB' 'drugX' 'drugY' 'drugY' 'drugB' 'drugB' 'drugY' 'drugX' 'drugY'\n",
      " 'drugY' 'drugX']\n",
      "train: ['drugY' 'drugC' 'drugC' 'drugX' 'drugY' 'drugY' 'drugC' 'drugY' 'drugY'\n",
      " 'drugC' 'drugY' 'drugY' 'drugX' 'drugY' 'drugX' 'drugC' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY'\n",
      " 'drugX' 'drugB' 'drugX' 'drugY' 'drugX' 'drugX' 'drugA' 'drugX' 'drugX'\n",
      " 'drugX' 'drugY' 'drugB' 'drugX' 'drugX' 'drugX' 'drugA' 'drugC' 'drugY'\n",
      " 'drugY' 'drugX' 'drugY' 'drugY' 'drugC' 'drugB' 'drugY' 'drugX' 'drugY'\n",
      " 'drugY' 'drugA' 'drugY' 'drugX' 'drugB' 'drugY' 'drugY' 'drugY' 'drugB'\n",
      " 'drugY' 'drugX' 'drugY' 'drugY' 'drugY' 'drugA' 'drugY' 'drugX' 'drugB'\n",
      " 'drugX' 'drugC' 'drugA' 'drugB' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugA'\n",
      " 'drugA' 'drugC' 'drugX' 'drugY' 'drugX' 'drugY' 'drugB' 'drugY' 'drugA'\n",
      " 'drugX' 'drugX' 'drugX' 'drugY' 'drugA' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugB' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugX' 'drugY'\n",
      " 'drugY' 'drugX' 'drugB' 'drugA' 'drugB' 'drugX' 'drugA' 'drugY' 'drugB'\n",
      " 'drugY' 'drugA' 'drugX' 'drugX' 'drugA' 'drugX' 'drugC' 'drugA' 'drugB'\n",
      " 'drugX' 'drugX' 'drugY' 'drugC' 'drugA' 'drugY' 'drugX' 'drugX' 'drugB'\n",
      " 'drugX' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugA' 'drugX' 'drugX'\n",
      " 'drugY' 'drugY' 'drugA' 'drugY' 'drugA' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugX' 'drugX' 'drugY' 'drugY' 'drugB' 'drugA' 'drugY' 'drugY' 'drugY'\n",
      " 'drugA' 'drugY' 'drugC' 'drugY' 'drugC' 'drugC' 'drugX' 'drugX' 'drugX'], test: ['drugX' 'drugY' 'drugA' 'drugY' 'drugY' 'drugB' 'drugA' 'drugX' 'drugA'\n",
      " 'drugC' 'drugY' 'drugX' 'drugX' 'drugX' 'drugX' 'drugY' 'drugX' 'drugC'\n",
      " 'drugY' 'drugY']\n",
      "train: ['drugY' 'drugC' 'drugC' 'drugX' 'drugY' 'drugX' 'drugY' 'drugC' 'drugY'\n",
      " 'drugY' 'drugC' 'drugY' 'drugY' 'drugX' 'drugY' 'drugX' 'drugA' 'drugC'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX'\n",
      " 'drugY' 'drugY' 'drugX' 'drugB' 'drugX' 'drugY' 'drugX' 'drugX' 'drugX'\n",
      " 'drugX' 'drugX' 'drugY' 'drugB' 'drugY' 'drugX' 'drugX' 'drugA' 'drugC'\n",
      " 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugB' 'drugC' 'drugB'\n",
      " 'drugY' 'drugX' 'drugY' 'drugY' 'drugA' 'drugY' 'drugX' 'drugB' 'drugY'\n",
      " 'drugA' 'drugX' 'drugY' 'drugY' 'drugB' 'drugY' 'drugX' 'drugY' 'drugY'\n",
      " 'drugY' 'drugA' 'drugY' 'drugA' 'drugX' 'drugB' 'drugA' 'drugC' 'drugB'\n",
      " 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX'\n",
      " 'drugY' 'drugY' 'drugY' 'drugA' 'drugA' 'drugC' 'drugY' 'drugX' 'drugX'\n",
      " 'drugY' 'drugB' 'drugY' 'drugA' 'drugX' 'drugX' 'drugX' 'drugX' 'drugY'\n",
      " 'drugX' 'drugX' 'drugA' 'drugY' 'drugY' 'drugY' 'drugY' 'drugB' 'drugY'\n",
      " 'drugY' 'drugX' 'drugY' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX'\n",
      " 'drugB' 'drugA' 'drugB' 'drugX' 'drugA' 'drugY' 'drugB' 'drugY' 'drugA'\n",
      " 'drugX' 'drugX' 'drugA' 'drugC' 'drugA' 'drugB' 'drugX' 'drugC' 'drugA'\n",
      " 'drugY' 'drugC' 'drugX' 'drugX' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugX' 'drugY' 'drugA' 'drugX' 'drugX' 'drugY' 'drugA' 'drugY' 'drugA'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugX' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugC' 'drugY' 'drugC' 'drugX' 'drugX'], test: ['drugY' 'drugA' 'drugX' 'drugX' 'drugC' 'drugY' 'drugY' 'drugX' 'drugY'\n",
      " 'drugX' 'drugX' 'drugX' 'drugY' 'drugB' 'drugY' 'drugB' 'drugA' 'drugA'\n",
      " 'drugC' 'drugX']\n",
      "train: ['drugC' 'drugX' 'drugY' 'drugX' 'drugC' 'drugY' 'drugY' 'drugC' 'drugY'\n",
      " 'drugY' 'drugY' 'drugX' 'drugY' 'drugX' 'drugA' 'drugC' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugX'\n",
      " 'drugB' 'drugX' 'drugY' 'drugX' 'drugX' 'drugA' 'drugX' 'drugX' 'drugX'\n",
      " 'drugY' 'drugB' 'drugY' 'drugX' 'drugX' 'drugX' 'drugC' 'drugY' 'drugY'\n",
      " 'drugY' 'drugX' 'drugY' 'drugY' 'drugB' 'drugB' 'drugY' 'drugX' 'drugY'\n",
      " 'drugY' 'drugA' 'drugX' 'drugB' 'drugA' 'drugX' 'drugY' 'drugY' 'drugY'\n",
      " 'drugX' 'drugY' 'drugY' 'drugA' 'drugA' 'drugX' 'drugB' 'drugX' 'drugC'\n",
      " 'drugA' 'drugC' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugA' 'drugA' 'drugC' 'drugX'\n",
      " 'drugY' 'drugX' 'drugX' 'drugY' 'drugB' 'drugY' 'drugA' 'drugX' 'drugX'\n",
      " 'drugX' 'drugY' 'drugX' 'drugX' 'drugA' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugB' 'drugY' 'drugY' 'drugX' 'drugY' 'drugX' 'drugY' 'drugX'\n",
      " 'drugY' 'drugY' 'drugX' 'drugB' 'drugA' 'drugB' 'drugX' 'drugA' 'drugY'\n",
      " 'drugB' 'drugY' 'drugA' 'drugX' 'drugX' 'drugA' 'drugX' 'drugC' 'drugB'\n",
      " 'drugX' 'drugY' 'drugA' 'drugY' 'drugC' 'drugX' 'drugX' 'drugB' 'drugX'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugA' 'drugX' 'drugX' 'drugY'\n",
      " 'drugY' 'drugA' 'drugY' 'drugA' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX'\n",
      " 'drugX' 'drugY' 'drugY' 'drugY' 'drugB' 'drugA' 'drugY' 'drugY' 'drugY'\n",
      " 'drugA' 'drugY' 'drugC' 'drugY' 'drugC' 'drugC' 'drugX' 'drugX' 'drugX'], test: ['drugY' 'drugC' 'drugY' 'drugY' 'drugA' 'drugC' 'drugY' 'drugY' 'drugB'\n",
      " 'drugY' 'drugY' 'drugB' 'drugY' 'drugY' 'drugX' 'drugY' 'drugA' 'drugX'\n",
      " 'drugC' 'drugX']\n",
      "train: ['drugY' 'drugC' 'drugC' 'drugX' 'drugY' 'drugX' 'drugY' 'drugC' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugX' 'drugA' 'drugC' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY'\n",
      " 'drugX' 'drugB' 'drugY' 'drugX' 'drugX' 'drugA' 'drugX' 'drugX' 'drugX'\n",
      " 'drugY' 'drugB' 'drugY' 'drugX' 'drugX' 'drugX' 'drugA' 'drugC' 'drugY'\n",
      " 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugB' 'drugC' 'drugB' 'drugY'\n",
      " 'drugX' 'drugY' 'drugY' 'drugA' 'drugY' 'drugX' 'drugB' 'drugY' 'drugA'\n",
      " 'drugX' 'drugY' 'drugY' 'drugB' 'drugY' 'drugX' 'drugY' 'drugY' 'drugA'\n",
      " 'drugY' 'drugA' 'drugX' 'drugB' 'drugX' 'drugC' 'drugC' 'drugB' 'drugX'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugA' 'drugC' 'drugX' 'drugX' 'drugX' 'drugY' 'drugB'\n",
      " 'drugY' 'drugA' 'drugX' 'drugX' 'drugX' 'drugX' 'drugY' 'drugX' 'drugX'\n",
      " 'drugA' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugB' 'drugX' 'drugY'\n",
      " 'drugX' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugX' 'drugB' 'drugA'\n",
      " 'drugB' 'drugX' 'drugA' 'drugY' 'drugB' 'drugA' 'drugX' 'drugX' 'drugC'\n",
      " 'drugA' 'drugB' 'drugX' 'drugX' 'drugY' 'drugC' 'drugA' 'drugY' 'drugC'\n",
      " 'drugX' 'drugB' 'drugX' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugA'\n",
      " 'drugX' 'drugY' 'drugY' 'drugA' 'drugY' 'drugA' 'drugY' 'drugY' 'drugY'\n",
      " 'drugX' 'drugY' 'drugY' 'drugY' 'drugB' 'drugA' 'drugY' 'drugY' 'drugY'\n",
      " 'drugA' 'drugY' 'drugC' 'drugY' 'drugC' 'drugC' 'drugX' 'drugX' 'drugX'], test: ['drugY' 'drugC' 'drugY' 'drugX' 'drugY' 'drugA' 'drugY' 'drugY' 'drugA'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugA' 'drugX' 'drugY' 'drugX'\n",
      " 'drugY' 'drugX']\n",
      "train: ['drugY' 'drugC' 'drugC' 'drugY' 'drugX' 'drugY' 'drugC' 'drugY' 'drugY'\n",
      " 'drugC' 'drugY' 'drugY' 'drugY' 'drugX' 'drugX' 'drugA' 'drugC' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugX'\n",
      " 'drugB' 'drugX' 'drugY' 'drugX' 'drugX' 'drugA' 'drugX' 'drugX' 'drugX'\n",
      " 'drugY' 'drugY' 'drugX' 'drugX' 'drugA' 'drugC' 'drugY' 'drugY' 'drugX'\n",
      " 'drugY' 'drugB' 'drugC' 'drugB' 'drugY' 'drugX' 'drugY' 'drugY' 'drugA'\n",
      " 'drugY' 'drugX' 'drugY' 'drugA' 'drugX' 'drugY' 'drugY' 'drugB' 'drugY'\n",
      " 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugA' 'drugX' 'drugX' 'drugC'\n",
      " 'drugA' 'drugC' 'drugB' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugA'\n",
      " 'drugA' 'drugC' 'drugX' 'drugY' 'drugX' 'drugX' 'drugY' 'drugB' 'drugA'\n",
      " 'drugX' 'drugX' 'drugX' 'drugY' 'drugX' 'drugX' 'drugA' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugB' 'drugY' 'drugY' 'drugX' 'drugY' 'drugX'\n",
      " 'drugY' 'drugX' 'drugY' 'drugY' 'drugB' 'drugA' 'drugB' 'drugX' 'drugA'\n",
      " 'drugY' 'drugB' 'drugY' 'drugA' 'drugX' 'drugX' 'drugA' 'drugX' 'drugA'\n",
      " 'drugX' 'drugX' 'drugY' 'drugC' 'drugA' 'drugY' 'drugC' 'drugX' 'drugX'\n",
      " 'drugB' 'drugX' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugX' 'drugX'\n",
      " 'drugY' 'drugY' 'drugA' 'drugY' 'drugA' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugX' 'drugX' 'drugY' 'drugY' 'drugY' 'drugB' 'drugA' 'drugY' 'drugY'\n",
      " 'drugA' 'drugY' 'drugC' 'drugY' 'drugC' 'drugC' 'drugX' 'drugX' 'drugX'], test: ['drugX' 'drugY' 'drugY' 'drugY' 'drugB' 'drugX' 'drugY' 'drugY' 'drugB'\n",
      " 'drugA' 'drugB' 'drugY' 'drugX' 'drugY' 'drugX' 'drugC' 'drugB' 'drugY'\n",
      " 'drugA' 'drugY']\n",
      "train: ['drugY' 'drugC' 'drugX' 'drugY' 'drugX' 'drugY' 'drugY' 'drugC' 'drugY'\n",
      " 'drugY' 'drugY' 'drugX' 'drugY' 'drugX' 'drugA' 'drugC' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugB'\n",
      " 'drugX' 'drugY' 'drugX' 'drugX' 'drugA' 'drugX' 'drugX' 'drugX' 'drugY'\n",
      " 'drugB' 'drugY' 'drugX' 'drugX' 'drugX' 'drugA' 'drugC' 'drugY' 'drugY'\n",
      " 'drugX' 'drugY' 'drugY' 'drugB' 'drugC' 'drugB' 'drugX' 'drugY' 'drugY'\n",
      " 'drugB' 'drugY' 'drugA' 'drugX' 'drugY' 'drugB' 'drugY' 'drugX' 'drugY'\n",
      " 'drugY' 'drugY' 'drugA' 'drugY' 'drugA' 'drugX' 'drugB' 'drugX' 'drugC'\n",
      " 'drugA' 'drugC' 'drugB' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugY' 'drugA' 'drugA' 'drugC'\n",
      " 'drugX' 'drugY' 'drugX' 'drugX' 'drugY' 'drugB' 'drugY' 'drugA' 'drugX'\n",
      " 'drugX' 'drugX' 'drugX' 'drugX' 'drugX' 'drugA' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugB' 'drugY' 'drugY' 'drugX' 'drugX' 'drugY' 'drugY' 'drugX'\n",
      " 'drugY' 'drugY' 'drugX' 'drugB' 'drugA' 'drugB' 'drugX' 'drugA' 'drugB'\n",
      " 'drugY' 'drugA' 'drugX' 'drugX' 'drugA' 'drugX' 'drugC' 'drugA' 'drugB'\n",
      " 'drugX' 'drugX' 'drugY' 'drugC' 'drugA' 'drugY' 'drugC' 'drugX' 'drugX'\n",
      " 'drugB' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugA'\n",
      " 'drugX' 'drugX' 'drugY' 'drugY' 'drugA' 'drugA' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugX' 'drugX' 'drugY' 'drugY' 'drugY' 'drugB' 'drugA' 'drugY'\n",
      " 'drugY' 'drugA' 'drugY' 'drugC' 'drugY' 'drugC' 'drugX' 'drugX' 'drugX'], test: ['drugC' 'drugC' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugY' 'drugA'\n",
      " 'drugX' 'drugY' 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugY' 'drugC']\n",
      "train: ['drugY' 'drugC' 'drugC' 'drugX' 'drugY' 'drugX' 'drugY' 'drugC' 'drugY'\n",
      " 'drugY' 'drugC' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugX' 'drugA'\n",
      " 'drugC' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY'\n",
      " 'drugY' 'drugX' 'drugB' 'drugX' 'drugY' 'drugX' 'drugX' 'drugA' 'drugX'\n",
      " 'drugX' 'drugY' 'drugB' 'drugY' 'drugX' 'drugX' 'drugX' 'drugA' 'drugC'\n",
      " 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugB' 'drugC' 'drugB'\n",
      " 'drugY' 'drugX' 'drugY' 'drugY' 'drugA' 'drugY' 'drugX' 'drugB' 'drugY'\n",
      " 'drugA' 'drugX' 'drugY' 'drugY' 'drugB' 'drugY' 'drugY' 'drugY' 'drugA'\n",
      " 'drugY' 'drugA' 'drugB' 'drugX' 'drugC' 'drugA' 'drugC' 'drugB' 'drugX'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX'\n",
      " 'drugY' 'drugY' 'drugY' 'drugY' 'drugA' 'drugC' 'drugX' 'drugY' 'drugX'\n",
      " 'drugX' 'drugY' 'drugB' 'drugY' 'drugA' 'drugX' 'drugX' 'drugX' 'drugX'\n",
      " 'drugY' 'drugX' 'drugX' 'drugA' 'drugY' 'drugY' 'drugY' 'drugY' 'drugY'\n",
      " 'drugB' 'drugY' 'drugY' 'drugX' 'drugY' 'drugY' 'drugY' 'drugX' 'drugX'\n",
      " 'drugB' 'drugB' 'drugY' 'drugY' 'drugX' 'drugA' 'drugX' 'drugC' 'drugA'\n",
      " 'drugB' 'drugX' 'drugX' 'drugY' 'drugC' 'drugC' 'drugX' 'drugX' 'drugB'\n",
      " 'drugX' 'drugY' 'drugY' 'drugY' 'drugY' 'drugX' 'drugY' 'drugA' 'drugX'\n",
      " 'drugX' 'drugY' 'drugY' 'drugA' 'drugY' 'drugA' 'drugY' 'drugY' 'drugY'\n",
      " 'drugX' 'drugX' 'drugY' 'drugY' 'drugY' 'drugB' 'drugA' 'drugY' 'drugY'\n",
      " 'drugY' 'drugA' 'drugC' 'drugY' 'drugC' 'drugC' 'drugX' 'drugX' 'drugX'], test: ['drugY' 'drugY' 'drugX' 'drugY' 'drugX' 'drugX' 'drugA' 'drugX' 'drugY'\n",
      " 'drugY' 'drugA' 'drugX' 'drugA' 'drugB' 'drugA' 'drugX' 'drugA' 'drugY'\n",
      " 'drugY' 'drugY']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(10, True, 1)\n",
    "\n",
    "for train, test in kfold.split(X):\n",
    "    print('train: %s, test: %s' % (X[train], X[test]))\n",
    "    \n",
    "for train, test in kfold.split(y):\n",
    "    print('train: %s, test: %s' % (y[train], y[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train X: 180, length of test X: 20\n"
     ]
    }
   ],
   "source": [
    "X_train_cv = X[train]\n",
    "X_test_cv = X[test]\n",
    "y_train_cv = y[train]\n",
    "y_test_cv = y[test]\n",
    "print(f'length of train X: {len(X_train_cv)}, length of test X: {len(X_test_cv)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['drugY', 'drugY', 'drugX', 'drugY', 'drugX', 'drugX', 'drugA',\n",
       "       'drugX', 'drugY', 'drugY', 'drugA', 'drugX', 'drugA', 'drugB',\n",
       "       'drugA', 'drugX', 'drugA', 'drugY', 'drugY', 'drugY'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rand_forest = RandomForestClassifier(n_estimators=200)\n",
    "rand_forest.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "y_pred_cv = rand_forest.predict(X_test_cv)\n",
    "y_pred_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Gini = 1.0\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test_cv, y_pred_cv)\n",
    "print(f\"Accuracy for Gini = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       1.00      1.00      1.00         5\n",
      "       drugB       1.00      1.00      1.00         1\n",
      "       drugX       1.00      1.00      1.00         6\n",
      "       drugY       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = classification_report(y_test_cv, y_pred_cv)\n",
    "\n",
    "print(f\"{cls_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 6 0]\n",
      " [0 0 0 8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm = confusion_matrix(y_test_cv, y_pred_cv)\n",
    "print(cfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fourth result: The accuracy given by cross validation is 100%, as this is the best method model by now to prevent overfitting.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Tree and Random Forest model are alternative models for classification dataset.\n",
    "- __Gini and Entropy yield same result__. Factors could be because our data only consist 200 data which is consider small. So no big difference.\n",
    "- Using the 'Decision Tree Model' with different 'random_state', by __increasing randomness in data we can obtain better accuracy__.\n",
    "- In this case, __the random forest gives less accuracy compare to decision tree model__, this could possibly __because underfitting__.\n",
    "- __The accuracy given by cross validation is 100%__, as this is the best method model by now to prevent overfitting. The confusion matrix perfectly fill all the diagonal area. The classification report also gives clear result for the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, all this models yiel accuracy > 95% which is very reliable in real world. \n",
    "\n",
    "By having the patient 'Age', 'Sex', 'Blood-Pressure rate', 'Cholesterol rate', and 'Sodium-Potassium rate'. We can predict using which drug medicine to cure the patient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

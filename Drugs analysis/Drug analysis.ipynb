{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have collected data about a set of patients, all of whom suffered from the same illness. During their course of treatment, each patient responded to one of 5 medications, Drug A, Drug B, Drug C, Drug X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>8.607</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>16.275</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>11.037</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>15.171</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>19.368</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0   23   F    HIGH        HIGH   25.355  drugY\n",
       "1   47   M     LOW        HIGH   13.093  drugC\n",
       "2   47   M     LOW        HIGH   10.114  drugC\n",
       "3   28   F  NORMAL        HIGH    7.798  drugX\n",
       "4   61   F     LOW        HIGH   18.043  drugY\n",
       "5   22   F  NORMAL        HIGH    8.607  drugX\n",
       "6   49   F  NORMAL        HIGH   16.275  drugY\n",
       "7   41   M     LOW        HIGH   11.037  drugC\n",
       "8   60   M  NORMAL        HIGH   15.171  drugY\n",
       "9   43   M     LOW      NORMAL   19.368  drugY"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "drug_data = pd.read_csv('drug200.csv')\n",
    "drug_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We want to try split into 2 different dataset (70% / 30%) and evaluate the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. We want to convert the string into label (Sex, BP, NA_to_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label = preprocessing.LabelEncoder()\n",
    "new_sex = label.fit_transform(drug_data['Sex'])\n",
    "#print(f\"sex_label = {new_sex}\")\n",
    "\n",
    "new_BP = label.fit_transform(drug_data['BP'])\n",
    "#print(f\"BP_label = {new_BP}\")\n",
    "\n",
    "new_Cholesterol = label.fit_transform(drug_data['Cholesterol'])\n",
    "#print(f\"Cholesterol_label = {new_Cholesterol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HIGH', 'NORMAL'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_data['Cholesterol'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert df into array so we can train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explanatory Variable (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23, 'F', 'HIGH', 'HIGH', 25.355],\n",
       "       [47, 'M', 'LOW', 'HIGH', 13.093],\n",
       "       [47, 'M', 'LOW', 'HIGH', 10.113999999999999]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = drug_data[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values\n",
    "X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23, 0, 0, 0, 25.355],\n",
       "       [47, 1, 1, 0, 13.093],\n",
       "       [47, 1, 1, 0, 10.113999999999999],\n",
       "       [28, 0, 2, 0, 7.797999999999999],\n",
       "       [61, 0, 1, 0, 18.043]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,1] = new_sex\n",
    "X[:,2] = new_BP\n",
    "X[:,3] = new_Cholesterol\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.29159102, -1.040833  , -1.11016894, -0.97043679,  1.28652212],\n",
       "       [ 0.16269866,  0.96076892,  0.10979693, -0.97043679, -0.4151454 ],\n",
       "       [ 0.16269866,  0.96076892,  0.10979693, -0.97043679, -0.82855818],\n",
       "       [-0.988614  , -1.040833  ,  1.32976279, -0.97043679, -1.14996267],\n",
       "       [ 1.0110343 , -1.040833  ,  0.10979693, -0.97043679,  0.27179427]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Response Variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['drugY', 'drugC', 'drugC'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = drug_data['Drug'].values\n",
    "y[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 = Gini Decision Tree Model (Random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model1 = DecisionTreeClassifier(criterion=\"gini\", max_depth = 4)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction output is ['drugX' 'drugY' 'drugX' 'drugC' 'drugY'], meanwhile the real output we have is ['drugX' 'drugY' 'drugX' 'drugC' 'drugY']\n"
     ]
    }
   ],
   "source": [
    "Model1.fit(X_train, y_train)\n",
    "y_pred_G = Model1.predict(X_test)\n",
    "print(f\"The prediction output is {y_pred_G[0:5]}, meanwhile the real output we have is {y_test[0:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 = Entropy Decision Tree Model (Random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=5,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model2 = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 5)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction output is ['drugX' 'drugY' 'drugX' 'drugC' 'drugY'], meanwhile the real output we have is ['drugX' 'drugY' 'drugX' 'drugC' 'drugY']\n"
     ]
    }
   ],
   "source": [
    "Model2.fit(X_train, y_train)\n",
    "y_pred_E = Model2.predict(X_test)\n",
    "print(f\"The prediction output is {y_pred_E[0:5]}, meanwhile the real output we have is {y_test[0:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation using accuracy and classification report (Max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Gini = 0.9833333333333333 & Accuracy for Entropy = 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc1 = accuracy_score(y_test, y_pred_G)\n",
    "acc2 = accuracy_score(y_test, y_pred_E)\n",
    "print(f\"Accuracy for Gini = {acc1} & Accuracy for Entropy = {acc2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.80      1.00      0.89         4\n",
      "       drugB       1.00      0.83      0.91         6\n",
      "       drugC       1.00      1.00      1.00         4\n",
      "       drugX       1.00      1.00      1.00        19\n",
      "       drugY       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           0.98        60\n",
      "   macro avg       0.96      0.97      0.96        60\n",
      "weighted avg       0.99      0.98      0.98        60\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.80      1.00      0.89         4\n",
      "       drugB       1.00      0.83      0.91         6\n",
      "       drugC       1.00      1.00      1.00         4\n",
      "       drugX       1.00      1.00      1.00        19\n",
      "       drugY       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           0.98        60\n",
      "   macro avg       0.96      0.97      0.96        60\n",
      "weighted avg       0.99      0.98      0.98        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cls_report1 = classification_report(y_test, y_pred_G)\n",
    "cls_report2 = classification_report(y_test, y_pred_E)\n",
    "\n",
    "print(f\"{cls_report1}\")\n",
    "print(f\"{cls_report2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  0  0  0]\n",
      " [ 1  5  0  0  0]\n",
      " [ 0  0  4  0  0]\n",
      " [ 0  0  0 19  0]\n",
      " [ 0  0  0  0 27]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred_G)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project decision tree model (model1 & model2) yield similar result. \n",
    "\n",
    "In theory, Entropy would yield better result due to its complexity. Whereas, Gini impurity is also pretty accurate with less latency due to straight forward split method (simpler computation).\n",
    "\n",
    "__First Result: Gini and Entropy yield same result. Factors could be because our data only consist 200 data (pharmacy).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, I found out that if we change the random_state in our decision tree model we can get better prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 = Decision Tree Model (Max_depth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since both Gini and Entropy yield same accuracy so we choose one here\n",
    "Model = DecisionTreeClassifier(criterion=\"gini\", max_depth = 3)\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction output is ['drugX' 'drugY' 'drugX' 'drugX' 'drugY'], meanwhile the real output we have is ['drugX' 'drugY' 'drugX' 'drugC' 'drugY']\n"
     ]
    }
   ],
   "source": [
    "Model.fit(X_train, y_train)\n",
    "y_pred_new = Model.predict(X_test)\n",
    "print(f\"The prediction output is {y_pred_new[0:5]}, meanwhile the real output we have is {y_test[0:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Gini = 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "acc1 = accuracy_score(y_test, y_pred_new)\n",
    "print(f\"Accuracy for Gini = {acc1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.80      1.00      0.89         4\n",
      "       drugB       1.00      0.83      0.91         6\n",
      "       drugC       0.00      0.00      0.00         4\n",
      "       drugX       0.83      1.00      0.90        19\n",
      "       drugY       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           0.92        60\n",
      "   macro avg       0.73      0.77      0.74        60\n",
      "weighted avg       0.86      0.92      0.89        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "cls_report = classification_report(y_test, y_pred_new)\n",
    "\n",
    "print(f\"{cls_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  0  0  0]\n",
      " [ 1  5  0  0  0]\n",
      " [ 0  0  0  4  0]\n",
      " [ 0  0  0 19  0]\n",
      " [ 0  0  0  0 27]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm = confusion_matrix(y_test, y_pred_new)\n",
    "print(cfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see when we lower the max depth from 5 to 3, it decreases the f1-score accuracy by 0.16 (0.98 to 0.82)\n",
    "\n",
    "The confusion matrix also explains positive correlation of this model.\n",
    "\n",
    "__Second result: Using the 'Decision Tree Model' with different 'max_depth', higher tree depth will yield higher accuracy.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, I want to model it using Random Forest, which normally will yield better accuracy rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 = Random Forest Model (Random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['drugX', 'drugY', 'drugX', 'drugC', 'drugY', 'drugX', 'drugX',\n",
       "       'drugY', 'drugY', 'drugY', 'drugX', 'drugC', 'drugY', 'drugY',\n",
       "       'drugA', 'drugA', 'drugX', 'drugX', 'drugB', 'drugY', 'drugX',\n",
       "       'drugX', 'drugX', 'drugY', 'drugB', 'drugX', 'drugX', 'drugY',\n",
       "       'drugX', 'drugX', 'drugC', 'drugY', 'drugY', 'drugY', 'drugA',\n",
       "       'drugY', 'drugA', 'drugY', 'drugY', 'drugY', 'drugB', 'drugY',\n",
       "       'drugY', 'drugX', 'drugB', 'drugY', 'drugX', 'drugX', 'drugY',\n",
       "       'drugB', 'drugY', 'drugY', 'drugY', 'drugY', 'drugY', 'drugY',\n",
       "       'drugX', 'drugX', 'drugX', 'drugA'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rand_forest = RandomForestClassifier(n_estimators=200)\n",
    "rand_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Gini = 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy for Gini = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.80      1.00      0.89         4\n",
      "       drugB       1.00      0.83      0.91         6\n",
      "       drugC       1.00      0.75      0.86         4\n",
      "       drugX       0.95      1.00      0.97        19\n",
      "       drugY       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           0.97        60\n",
      "   macro avg       0.95      0.92      0.93        60\n",
      "weighted avg       0.97      0.97      0.97        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"{cls_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  0  0  0]\n",
      " [ 1  5  0  0  0]\n",
      " [ 0  0  3  1  0]\n",
      " [ 0  0  0 19  0]\n",
      " [ 0  0  0  0 27]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm = confusion_matrix(y_test, y_pred)\n",
    "print(cfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Third result: In this case, the random forest gives a bit less accuracy compare to decision tree model (max_depth = 5), this could possibly cause underfitting.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas normally __'Random Forest model'__ will give much better accuracy than __'Decision Tree model'__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So we can try use __cross validation method on 4 different models (K-fold Library)__ and check the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 :  Decision Tree (K-fold) on different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create different model that **age, gender** dependent only with **BP**, **Na_to_K** and **Cholesterol** only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model depend on BP\n",
    "X_BP = drug_data[['Age', 'Sex', 'BP']].values\n",
    "X_BP[:,1] = new_sex\n",
    "X_BP[:,2] = new_BP\n",
    "X_BP= preprocessing.StandardScaler().fit(X_BP).transform(X_BP)\n",
    "\n",
    "# Model depend on Cholesterol\n",
    "X_Chol = drug_data[['Age', 'Sex', 'Cholesterol']].values\n",
    "X_Chol[:,1] = new_sex\n",
    "X_Chol[:,2] = new_Cholesterol\n",
    "X_Chol= preprocessing.StandardScaler().fit(X_Chol).transform(X_Chol)\n",
    "\n",
    "# Model depend on Na_to_K\n",
    "X_NaK = drug_data[['Age', 'Sex', 'Na_to_K']].values\n",
    "X_NaK[:,1] = new_sex\n",
    "X_NaK= preprocessing.StandardScaler().fit(X_NaK).transform(X_NaK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(10, True, 1)\n",
    "\n",
    "for train, test in kfold.split(X_BP):\n",
    "    X_train_BP = X_BP[train]\n",
    "    X_test_BP = X_BP[test]\n",
    "    # print('train: %s, test: %s' % (X[train], X[test]))\n",
    "\n",
    "for train, test in kfold.split(X_Chol):\n",
    "    X_train_Chol = X_Chol[train]\n",
    "    X_test_Chol = X_Chol[test]\n",
    "\n",
    "for train, test in kfold.split(X_NaK):\n",
    "    X_train_NaK = X_NaK[train]\n",
    "    X_test_NaK = X_NaK[test]\n",
    "\n",
    "for train, test in kfold.split(X):\n",
    "    X_train_cv = X[train]\n",
    "    X_test_cv = X[test]\n",
    "    \n",
    "for train, test in kfold.split(y):\n",
    "    y_train_cv = y[train]\n",
    "    y_test_cv = y[test]\n",
    "    # print('train: %s, test: %s' % (y[train], y[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best max_depth 5\n",
    "Model1 = DecisionTreeClassifier(criterion=\"gini\", max_depth = 5)\n",
    "Model2 = DecisionTreeClassifier(criterion=\"gini\", max_depth = 5)\n",
    "Model3 = DecisionTreeClassifier(criterion=\"gini\", max_depth = 5)\n",
    "Model4 = DecisionTreeClassifier(criterion=\"gini\", max_depth = 5)\n",
    "\n",
    "Model1.fit(X_train_BP, y_train_cv)\n",
    "Model2.fit(X_train_Chol, y_train_cv)\n",
    "Model3.fit(X_train_NaK, y_train_cv)\n",
    "Model4.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "\n",
    "y1_pred = Model1.predict(X_test_BP)\n",
    "y2_pred = Model2.predict(X_test_Chol)\n",
    "y3_pred = Model3.predict(X_test_NaK)\n",
    "y4_pred = Model4.predict(X_test_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BP', 'Cholesterol', 'Na_to_K', 'all']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_name = drug_data.columns[2:5].to_list()\n",
    "column_name.append(\"all\")\n",
    "column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for BP: 0.5, which has confusion matrix \n",
      " [[1 0 0 0 4]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 1 3 2]\n",
      " [0 0 0 3 5]]\n",
      "\n",
      "Accuracy for Cholesterol: 0.3, which has confusion matrix \n",
      " [[0 0 0 2 3]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 1 1 4]\n",
      " [0 1 0 2 5]]\n",
      "\n",
      "Accuracy for Na_to_K: 0.7, which has confusion matrix \n",
      " [[1 0 4 0]\n",
      " [0 0 1 0]\n",
      " [0 1 5 0]\n",
      " [0 0 0 8]]\n",
      "\n",
      "Accuracy for all: 1.0, which has confusion matrix \n",
      " [[5 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 6 0]\n",
      " [0 0 0 8]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [y1_pred, y2_pred, y3_pred, y4_pred]\n",
    "\n",
    "a= []\n",
    "b= []\n",
    "nl = \"\\n\"\n",
    "\n",
    "for i,k,s in zip(y_pred, range(0,4), column_name):\n",
    "    a.append(accuracy_score(y_test_cv,i)) \n",
    "    b.append(confusion_matrix(y_test_cv,i))\n",
    "    print(f\"Accuracy for {s}: {a[k]}, which has confusion matrix {nl} {b[k]}{nl}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fourth result: The accuracy using kfold split given by__\n",
    "- All input is 100%,\n",
    "- Na_to_K is 70%,\n",
    "- BP is 50%,\n",
    "- Cholesterol 30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Tree and Random Forest model are alternative models for classification dataset.\n",
    "- __Gini and Entropy yield same result__. Factors could be because our data only consist 200 data which is consider small. So no big difference.\n",
    "- Using the 'Decision Tree Model' with different 'max_depth', might __change the accuracy of the model__.\n",
    "- In this case, __the random forest gives a bit less accuracy compare to decision tree model with max_depth-5__, this could possibly __because underfitting__.\n",
    "- __The accuracy given by k-fold split for all input is 100%__, as this is the best method model by now to prevent overfitting. The confusion matrix perfectly fill all the diagonal area. The classification report also gives clear result for the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, with all inputs with optimize model could yiel a 100% prediction accuracy however the limitation of this project, the perfect result could due to small dataset.\n",
    "\n",
    "By having the patient 'Age', 'Sex', 'Blood-Pressure rate', 'Cholesterol rate', and 'Sodium-Potassium rate'. We can predict using which drug medicine to cure the patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
